{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.1 Import libraries\n",
    "import math\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib.learn.python.learn.datasets.mnist import read_data_sets\n",
    "\n",
    "% matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 2.2 Define some constants\n",
    "# The MNIST dataset has 10 classes, representing the digits 0 through 9\n",
    "NUM_CLASSES = 10\n",
    "\n",
    "# The MNIST images are always 28x28 pixels\n",
    "IMAGE_SIZE = 28\n",
    "IMAGE_PIXELS = IMAGE_SIZE * IMAGE_SIZE\n",
    "\n",
    "# Batch size. Must be evenly divedeagle by dataset sizes.\n",
    "BATCH_SIZE = 100\n",
    "EVAL_BATCH_SIZE = 1\n",
    "\n",
    "# Number of units in hidden layers\n",
    "HIDDEN1_UNITS = 128\n",
    "HIDDEN2_UNITS = 32\n",
    "\n",
    "# Maximum number of training steps\n",
    "MAX_STEPS = 2000\n",
    "\n",
    "# Directory to put the training data.\n",
    "TRAIN_DIR = \"/tmp/mnist\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/mnist\\train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/mnist\\train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/mnist\\t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/mnist\\t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# 2.3 Get input data: get the sets of images and labels for training, validatest test on MNIST.\n",
    "data_sets = read_data_sets(TRAIN_DIR, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 2.4 Build ingerence graph.\n",
    "def mnist_inference(images, hidden1_units, hidden2_units):\n",
    "    '''\n",
    "    Build the MNIST model up to where it may be used for inference.\n",
    "    Args:\n",
    "        images: Image placeholder\n",
    "        hidden1_units: Size of the first hidden layer\n",
    "        hidden2_units: Size of the sencond hidden layer\n",
    "    Returns:\n",
    "        logits: Output tensor with the computed logits\n",
    "    '''\n",
    "    # Hidden 1\n",
    "    with tf.name_scope('hidden1'):\n",
    "        weights = tf.Variable(tf.truncated_normal(\n",
    "            [IMAGE_PIXELS, hidden1_units],\n",
    "            stddev = 1.0 / math.sqrt(float(IMAGE_PIXELS))\n",
    "        ), name = 'weights')\n",
    "        biases = tf.Variable(tf.zeros([hidden1_units]), name = 'biases')\n",
    "        hidden1 = tf.nn.relu(tf.matmul(images, weights) + biases)\n",
    "    # Hidden 2\n",
    "    with tf.name_scope('hidden2'):\n",
    "        weights = tf.Variable(tf.truncated_normal(\n",
    "            [hidden1_units, hidden2_units],\n",
    "            stddev = 1.0 / math.sqrt(float(hidden1_units))\n",
    "        ), name = 'weights')\n",
    "        biases = tf.Variable(tf.zeros([hidden2_units]), name = 'biases')\n",
    "        hidden2 = tf.nn.relu(tf.matmul(hidden1, weights) + biases)\n",
    "    # Linear\n",
    "    with tf.name_scope('softmax_linear'):\n",
    "        weights = tf.Variable(tf.truncated_normal(\n",
    "            [hidden2_units, NUM_CLASSES],\n",
    "            stddev = 1.0 / math.sqrt(float(hidden2_units))\n",
    "        ), name = 'weights')\n",
    "        biases = tf.Variable(tf.zeros([NUM_CLASSES]), name = 'biases')\n",
    "        logits = tf.matmul(hidden2, weights) + biases\n",
    "        \n",
    "    return logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 2.5 Build training graph\n",
    "def mnist_training(logits, labels, learning_rate):\n",
    "    '''\n",
    "    Build the training graph\n",
    "    Args:\n",
    "        logits: Logits tensor, float - [BATCH_SIZE, NUM_CLASSES]\n",
    "        labels: Labels tensor, int32 - [BATCH_SIZE], with values in the range [0, NUM_CLASSES)\n",
    "        learning_rate: The learning rate to use for gradient descent\n",
    "    Returns:\n",
    "        train_op: The Op for training.\n",
    "        loss: The op for calculating loss\n",
    "    '''\n",
    "    # Create an operation that calculates loss\n",
    "    labels = tf.to_int64(labels)\n",
    "    cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(logits = logits, labels = labels, name = 'xentrory')\n",
    "    loss = tf.reduce_mean(cross_entropy, name = 'xentropy_mean')\n",
    "    # Create the gradient descent optimizer with the given learning rate\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "    # Create a varaible to track the global step\n",
    "    global_step = tf.Variable(0, name = 'global_step', trainable = False)\n",
    "    # Use the optimizer to apply the gradients that minimize the loss\n",
    "    # (and alos increament the global step counter) as a single training step\n",
    "    train_op = optimizer.minimize(loss, global_step = global_step)\n",
    "    \n",
    "    return train_op, loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\hjkim\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\tf_should_use.py:170: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\hjkim\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\tf_should_use.py:170: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n"
     ]
    }
   ],
   "source": [
    "# 2.6 Build the complete graph for feeding inputs, raining, and saving checkpoints\n",
    "mnist_graph = tf.Graph()\n",
    "with mnist_graph.as_default():\n",
    "    # Generate placeholders for the images and labels\n",
    "    images_placeholder = tf.placeholder(tf.float32)\n",
    "    labels_placeholder = tf.placeholder(tf.int32)\n",
    "    tf.add_to_collection('images', images_placeholder)\n",
    "    tf.add_to_collection('labels', labels_placeholder)\n",
    "    \n",
    "    # Build a graph that compute predictions from the inference model\n",
    "    logits = mnist_inference(images_placeholder, HIDDEN1_UNITS, HIDDEN2_UNITS)\n",
    "    tf.add_to_collection('logits', logits)\n",
    "    \n",
    "    # Add to the graph ops that calculate and apply gradients\n",
    "    train_op, loss = mnist_training(logits, labels_placeholder, 0.01)\n",
    "    \n",
    "    # Add the varaible initializer Op\n",
    "    init = tf.initialize_all_variables()\n",
    "    #init = tf.global_variables_initializer()\n",
    "    \n",
    "    # Create a saver for writing training ceheckpoints\n",
    "    saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0: loss = 2.31\n",
      "Step 100: loss = 2.17\n",
      "Step 200: loss = 1.97\n",
      "Step 300: loss = 1.67\n",
      "Step 400: loss = 1.33\n",
      "Step 500: loss = 1.21\n",
      "Step 600: loss = 0.91\n",
      "Step 700: loss = 0.79\n",
      "Step 800: loss = 0.67\n",
      "Step 900: loss = 0.66\n",
      "Step 1000: loss = 0.62\n",
      "Step 1100: loss = 0.47\n",
      "Step 1200: loss = 0.51\n",
      "Step 1300: loss = 0.48\n",
      "Step 1400: loss = 0.39\n",
      "Step 1500: loss = 0.54\n",
      "Step 1600: loss = 0.34\n",
      "Step 1700: loss = 0.37\n",
      "Step 1800: loss = 0.35\n",
      "Step 1900: loss = 0.44\n"
     ]
    }
   ],
   "source": [
    "# 2.7 Run training for MAX_STEPS and save checkpoint at the end\n",
    "with tf.Session(graph = mnist_graph) as sess:\n",
    "    # Run the op to initialize the variables\n",
    "    sess.run(init)\n",
    "    \n",
    "    # Start the training loop\n",
    "    for step in range(MAX_STEPS):\n",
    "        # Read a batch of images and labels\n",
    "        images_feed, labels_feed = data_sets.train.next_batch(BATCH_SIZE)\n",
    "        \n",
    "        # Run one step of the model. The return values are the activations\n",
    "        # from the `train_op` (which is discarded) adn the `loss` op. To\n",
    "        # inspect the values of  your ops or variables, you may include them\n",
    "        # in the list passed to sess.run() and the vlaue tensors will be\n",
    "        # returned int eh tuple from the call.\n",
    "        _, loss_value = sess.run(\n",
    "            [train_op, loss],\n",
    "            feed_dict = {\n",
    "                images_placeholder: images_feed,\n",
    "                labels_placeholder: labels_feed\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        # Print out loss value\n",
    "        if step % 100 == 0:\n",
    "            print('Step %d: loss = %.2f' % (step, loss_value))\n",
    "    \n",
    "    # Write a checkpoint\n",
    "    checkpoint_file = os.path.join(TRAIN_DIR, 'checkpoint')\n",
    "    saver.save(sess, checkpoint_file, global_step = step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /tmp/mnist\\checkpoint-1999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /tmp/mnist\\checkpoint-1999\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ground true: 2\\Pnrediction: 2\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\npf8/Qj3F7DEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x111b7f98>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 2.9 Run evaluation based on the saved checkpoint.\n",
    "with tf.Session(graph = tf.Graph()) as sess:\n",
    "    saver = tf.train.import_meta_graph(\n",
    "        os.path.join(TRAIN_DIR, \"checkpoint-1999.meta\")\n",
    "    )\n",
    "    saver.restore(\n",
    "        sess, os.path.join(TRAIN_DIR, 'checkpoint-1999')\n",
    "    )\n",
    "    \n",
    "    # Retrieve the ops we remembered\n",
    "    logits = tf.get_collection('logits')[0]\n",
    "    images_placeholder = tf.get_collection('images')[0]\n",
    "    labels_placeholder = tf.get_collection('labels')[0]\n",
    "    \n",
    "    # Add an op that chooses the top k predictions\n",
    "    eval_op = tf.nn.top_k(logits)\n",
    "    \n",
    "    # Run evaluation\n",
    "    images_feed, labels_feed = data_sets.validation.next_batch(EVAL_BATCH_SIZE)\n",
    "    imgplot = plt.imshow(np.reshape(images_feed, (28, 28)))\n",
    "    prediction = sess.run(eval_op, feed_dict = {\n",
    "        images_placeholder: images_feed,\n",
    "        labels_placeholder: labels_feed\n",
    "    })\n",
    "    print('Ground true: %d\\Pnrediction: %d' % (labels_feed, prediction.indices[0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
