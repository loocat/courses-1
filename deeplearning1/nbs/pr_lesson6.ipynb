{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lesson 6\n",
    "\n",
    "[lesson 6 wiki](http://wiki.fast.ai/index.php/Lesson_6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import utils\n",
    "import imp\n",
    "imp.reload(utils)\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "We're going to download the collected works of Nietzsche to use a sout data for this class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corpus length: 600893\n"
     ]
    }
   ],
   "source": [
    "path = get_file('nietzsche.txt', origin='http://s3.amazonaws.com/text-datasets/nietzsche.txt')\n",
    "text = open(path).read()\n",
    "print('corpus length:', len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total chars 85\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars) + 1\n",
    "print('total chars', vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes it's useful to have zero value in the dataset, e.g. for padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "chars.insert(0, '\\0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n !\"\\'(),-.0123456789:;=?ABCDEFGHIJKLMNOPQRSTUVWXYZ[]_abcdefghijklmnopqrstuvwxy'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''.join(chars[1:-6])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Map from chars to indices and back again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*idx* will be the data we use from now own - it simply converts all the characters to their index (based on the mapping above)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "idx = [char_indices[c] for c in text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[40, 42, 29, 30, 25, 27, 29, 1, 1, 1]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'PREFACE\\n\\n\\nSUPPOSING that Truth is a woman--what then? Is there not gro'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''.join(indices_char[i] for i in idx[:70])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 char model\n",
    "\n",
    "### create inputs\n",
    "\n",
    "Create a list of every 4th character, starting at the 0th, 1st, 2nd, then 3rd characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cs = 3\n",
    "c1_dat = [idx[i] for i in range(0, len(idx) - 1 - cs, cs)]\n",
    "c2_dat = [idx[i+1] for i in range(0, len(idx) - 1 - cs, cs)]\n",
    "c3_dat = [idx[i+2] for i in range(0, len(idx) - 1 - cs, cs)]\n",
    "c4_dat = [idx[i+3] for i in range(0, len(idx) - 1 - cs, cs)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x1 = np.stack(c1_dat[:-2])\n",
    "x2 = np.stack(c2_dat[:-2])\n",
    "x3 = np.stack(c3_dat[:-2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = np.stack(c4_dat[:-2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first 4 inputs and outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([40, 30, 29,  1]), array([42, 25,  1, 43]), array([29, 27,  1, 45]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1[:4], x2[:4], x3[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([30, 29,  1, 40])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((200295,), (200295,))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of latent factors to create (i.e. the size of the embedding matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_fac = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create inpus and embedding outputs for each our 3 character inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def embedding_input(name, n_in, n_out):\n",
    "    inp = Input(shape = (1,), dtype = 'int64', name = name)\n",
    "    emb = Embedding(n_in, n_out, input_length = 1)(inp)\n",
    "    return inp, Flatten()(emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c1_in, c1 = embedding_input('c1', vocab_size, n_fac)\n",
    "c2_in, c2 = embedding_input('c2', vocab_size, n_fac)\n",
    "c3_in, c3 = embedding_input('c3', vocab_size, n_fac)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create and train model\n",
    "\n",
    "Pick a size for out hidden state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_hidden = 256"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the 'green arrow' from our diagram - the layer operation from input to hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dense_in = Dense(n_hidden, activation = 'relu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our first hidden activation is simply this function applied to the result of the embedding of the first character."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c1_hidden = dense_in(c1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the 'orange arrow' from our diagram - the layer operation from hidden to hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dense_hidden = Dense(n_hidden, activation = 'tanh')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our second and third hidden activations sum up the previous hidden state (agter applying dense_hidden) to the new input state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hjkim\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\hjkim\\Anaconda3\\lib\\site-packages\\keras-2.0.8-py3.6.egg\\keras\\legacy\\layers.py:458: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n"
     ]
    }
   ],
   "source": [
    "c2_dense = dense_in(c2)\n",
    "hidden_2 = dense_hidden(c1_hidden)\n",
    "c2_hidden = merge([c2_dense, hidden_2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hjkim\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\hjkim\\Anaconda3\\lib\\site-packages\\keras-2.0.8-py3.6.egg\\keras\\legacy\\layers.py:458: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n"
     ]
    }
   ],
   "source": [
    "c3_dense = dense_in(c3)\n",
    "hidden_3 = dense_hidden(c2_hidden)\n",
    "c3_hidden = merge([c3_dense, hidden_3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the 'blue arrow' from out diagram - the layer operation from hidden to output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dense_out = Dense(vocab_size, activation = 'softmax')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The third hidden state is the inupt to our output layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c4_out = dense_out(c3_hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Model([c1_in, c2_in, c3_in], c4_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss = 'sparse_categorical_crossentropy', optimizer = Adam())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.optimizer.lr = 1e-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "200295/200295 [==============================] - 37s - loss: 4.4087    \n",
      "Epoch 2/4\n",
      "200295/200295 [==============================] - 35s - loss: 4.2864    \n",
      "Epoch 3/4\n",
      "200295/200295 [==============================] - 35s - loss: 4.0228    \n",
      "Epoch 4/4\n",
      "200295/200295 [==============================] - 35s - loss: 3.6240    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1361ad68>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit([x1, x2, x3], y, batch_size = 64, epochs = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.optimizer.kr = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "200295/200295 [==============================] - 35s - loss: 3.3161    \n",
      "Epoch 2/4\n",
      "200295/200295 [==============================] - 35s - loss: 3.1902    \n",
      "Epoch 3/4\n",
      "200295/200295 [==============================] - 35s - loss: 3.1411    \n",
      "Epoch 4/4\n",
      "200295/200295 [==============================] - 35s - loss: 3.1173    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x5e5e048>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit([x1, x2, x3], y, batch_size = 64, epochs = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.optimizer.lr = 1e-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "200295/200295 [==============================] - 35s - loss: 3.1026    \n",
      "Epoch 2/4\n",
      "200295/200295 [==============================] - ETA: 0s - loss: 3.091 - 35s - loss: 3.0918    \n",
      "Epoch 3/4\n",
      "200295/200295 [==============================] - 36s - loss: 3.0828    \n",
      "Epoch 4/4\n",
      "200295/200295 [==============================] - 35s - loss: 3.0748    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1361a9e8>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit([x1, x2, x3], y, batch_size = 64, epochs = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.optimizer.lr = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "200295/200295 [==============================] - 35s - loss: 3.0672    \n",
      "Epoch 2/4\n",
      "200295/200295 [==============================] - 35s - loss: 3.0600    \n",
      "Epoch 3/4\n",
      "200295/200295 [==============================] - 36s - loss: 3.0528    \n",
      "Epoch 4/4\n",
      "200295/200295 [==============================] - 35s - loss: 3.0455    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x116b5e80>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit([x1, x2, x3], y, batch_size = 64, epochs = 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_next(inp):\n",
    "    idxs = [char_indices[c] for c in inp]\n",
    "    arrs = [np.array(i)[np.newaxis] for i in idxs]\n",
    "    p = model.predict(arrs)\n",
    "    i = np.argmax(p)\n",
    "    return chars[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' '"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_next('phi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' '"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_next(' th')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' '"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_next(' an')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Out first RNN!\n",
    "\n",
    "### Create inputs\n",
    "\n",
    "This is the size of out unrolled RNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cs = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each of 0 through 7, create a list of every 8th character with taht starting point. These will be the 8 inputs to out model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c_in_dat = [[idx[i+n] for i in range(0, len(idx)-1-cs, cs)] for n in range(cs)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then create a list of the next character in each of these series. This will be the labels for our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c_out_dat = [idx[i+cs] for i in range(0, len(idx)-1-cs, cs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xs = [np.stack(c[:-2]) for c in c_in_dat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, (75109,))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(xs), xs[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = np.stack(c_out_dat[:-2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So each column below is one series of 8 characters from the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([40,  1, 33,  2, 72, 67, 73,  2]),\n",
       " array([42,  1, 38, 44,  2,  9, 61, 73]),\n",
       " array([29, 43, 31, 71, 54,  9, 58, 61]),\n",
       " array([30, 45,  2, 74,  2, 76, 67, 58]),\n",
       " array([25, 40, 73, 73, 76, 61, 24, 71]),\n",
       " array([27, 40, 61, 61, 68, 54,  2, 58]),\n",
       " array([29, 39, 54,  2, 66, 73, 33,  2]),\n",
       " array([ 1, 43, 73, 62, 54,  2, 72, 67])]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[xs[n][:cs] for n in range(cs)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "..and this is the next character after each sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1, 33,  2, 72, 67, 73,  2, 68])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[:cs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_fac = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create and train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def embedding_input(name, n_in, n_out) :\n",
    "    inp = Input(shape = (1,), dtype = 'int64', name = name + '_in')\n",
    "    emb = Embedding(n_in, n_out, input_length = 1, name = name + '_emb')(inp)\n",
    "    return inp, Flatten()(emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c_ins = [embedding_input('c' + str(n), vocab_size, n_fac) for n in range(cs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_hidden = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dense_in = Dense(n_hidden, activation = 'relu')\n",
    "dense_hidden = Dense(n_hidden, activation = 'relu', kernel_initializer = 'identity')\n",
    "dense_out = Dense(vocab_size, activation = 'softmax')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first character of each sequence goes through dense_in(), to create out first hidden activations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hidden = dense_in(c_ins[0][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then for each successive layer we combine the output of dense_in() on the next character with the output of dense_hidden() on the current hidden state, to create new hidden state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hjkim\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\Users\\hjkim\\Anaconda3\\lib\\site-packages\\keras-2.0.8-py3.6.egg\\keras\\legacy\\layers.py:458: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, cs):\n",
    "    c_dense = dense_in(c_ins[i][1])\n",
    "    hidden = dense_hidden(hidden)\n",
    "    hidden = merge([c_dense, hidden])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Putting the final hidden state through desnse_out() gives us our output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c_out = dense_out(hidden)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now we can create out model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Model([c[0] for c in c_ins], c_out)\n",
    "model.compile(loss = 'sparse_categorical_crossentropy', optimizer = Adam())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n",
      "75109/75109 [==============================] - 27s - loss: 2.5321    \n",
      "Epoch 2/12\n",
      "75109/75109 [==============================] - 25s - loss: 2.2489    \n",
      "Epoch 3/12\n",
      "75109/75109 [==============================] - 24s - loss: 2.1464    \n",
      "Epoch 4/12\n",
      "75109/75109 [==============================] - 27s - loss: 2.0778    \n",
      "Epoch 5/12\n",
      "75109/75109 [==============================] - 29s - loss: 2.0233    \n",
      "Epoch 6/12\n",
      "75109/75109 [==============================] - 26s - loss: 1.9773    \n",
      "Epoch 7/12\n",
      "75109/75109 [==============================] - 25s - loss: 1.9370    \n",
      "Epoch 8/12\n",
      "75109/75109 [==============================] - 31s - loss: 1.8995    \n",
      "Epoch 9/12\n",
      "75109/75109 [==============================] - 30s - loss: 1.8671    \n",
      "Epoch 10/12\n",
      "75109/75109 [==============================] - 30s - loss: 1.8386    \n",
      "Epoch 11/12\n",
      "75109/75109 [==============================] - 28s - loss: 1.8121    \n",
      "Epoch 12/12\n",
      "75109/75109 [==============================] - 24s - loss: 1.7867    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x12750fd0>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(xs, y, batch_size = 64, epochs = 12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_next(inp):\n",
    "    idxs = [np.array(char_indices[c])[np.newaxis] for c in inp]\n",
    "    p = model.predict(idxs)\n",
    "    return chars[np.argmax(p)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'e'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_next('for thos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'t'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_next('part of ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'n'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_next('queens a')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Our first RNN with keras!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_hidden, n_fac, cs, vocab_size = (256, 42, 8, 86)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is nearly exactly equivalent to the RNN we built ourselves in the previous section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hjkim\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `SimpleRNN` call to the Keras 2 API: `SimpleRNN(256, activation=\"relu\", recurrent_initializer=\"identity\")`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Embedding(vocab_size, n_fac, input_length = cs),\n",
    "    SimpleRNN(n_hidden, activation = 'relu', inner_init = 'identity'),\n",
    "    Dense(vocab_size, activation = 'softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (None, 8, 42)             3612      \n",
      "_________________________________________________________________\n",
      "simple_rnn_1 (SimpleRNN)     (None, 256)               76544     \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 86)                22102     \n",
      "=================================================================\n",
      "Total params: 102,258\n",
      "Trainable params: 102,258\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss = 'sparse_categorical_crossentropy', optimizer = Adam())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "75109/75109 [==============================] - 28s - loss: 2.7839    \n",
      "Epoch 2/8\n",
      "75109/75109 [==============================] - 26s - loss: 2.2702    \n",
      "Epoch 3/8\n",
      "75109/75109 [==============================] - 26s - loss: 2.0707    - ETA: \n",
      "Epoch 4/8\n",
      "75109/75109 [==============================] - 26s - loss: 1.9292    \n",
      "Epoch 5/8\n",
      "75109/75109 [==============================] - 26s - loss: 1.8223    \n",
      "Epoch 6/8\n",
      "75109/75109 [==============================] - 26s - loss: 1.7417    - ETA: 0s - \n",
      "Epoch 7/8\n",
      "75109/75109 [==============================] - 26s - loss: 1.6738    \n",
      "Epoch 8/8\n",
      "75109/75109 [==============================] - 27s - loss: 1.6192    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x168f8b70>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(np.concatenate(xs, axis = 1), y, batch_size = 64, epochs = 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_next_keras(inp):\n",
    "    idxs = [char_indices[c] for c in inp]\n",
    "    arrs = np.array(idxs)[np.newaxis,:]\n",
    "    p = model.predict(arrs)[0]\n",
    "    return chars[np.argmax(p)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_next_keras('this is ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'t'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_next_keras('part of ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'n'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_next_keras('queens a')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Returning sequeces\n",
    "\n",
    "### Create inputs\n",
    "\n",
    "To use a sequence model, we can leave out input unchanged - but we have to change out output to a sequence (of course!)\n",
    "\n",
    "Here, c_out_dat is identical to c_in_dat, but moved across 1 character,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c_out_dat = [[idx[i+n] for i in range(1, len(idx)-cs, cs)] for n in range(cs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ys = [np.stack(c[:-2]) for c in c_out_dat]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading down each column shows one set of inputs and outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[40],\n",
       "        [ 1],\n",
       "        [33],\n",
       "        [ 2],\n",
       "        [72],\n",
       "        [67],\n",
       "        [73],\n",
       "        [ 2]]), array([[42],\n",
       "        [ 1],\n",
       "        [38],\n",
       "        [44],\n",
       "        [ 2],\n",
       "        [ 9],\n",
       "        [61],\n",
       "        [73]]), array([[29],\n",
       "        [43],\n",
       "        [31],\n",
       "        [71],\n",
       "        [54],\n",
       "        [ 9],\n",
       "        [58],\n",
       "        [61]]), array([[30],\n",
       "        [45],\n",
       "        [ 2],\n",
       "        [74],\n",
       "        [ 2],\n",
       "        [76],\n",
       "        [67],\n",
       "        [58]]), array([[25],\n",
       "        [40],\n",
       "        [73],\n",
       "        [73],\n",
       "        [76],\n",
       "        [61],\n",
       "        [24],\n",
       "        [71]]), array([[27],\n",
       "        [40],\n",
       "        [61],\n",
       "        [61],\n",
       "        [68],\n",
       "        [54],\n",
       "        [ 2],\n",
       "        [58]]), array([[29],\n",
       "        [39],\n",
       "        [54],\n",
       "        [ 2],\n",
       "        [66],\n",
       "        [73],\n",
       "        [33],\n",
       "        [ 2]]), array([[ 1],\n",
       "        [43],\n",
       "        [73],\n",
       "        [62],\n",
       "        [54],\n",
       "        [ 2],\n",
       "        [72],\n",
       "        [67]])]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[xs[n][:cs] for n in range(cs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([42,  1, 38, 44,  2,  9, 61, 73]),\n",
       " array([29, 43, 31, 71, 54,  9, 58, 61]),\n",
       " array([30, 45,  2, 74,  2, 76, 67, 58]),\n",
       " array([25, 40, 73, 73, 76, 61, 24, 71]),\n",
       " array([27, 40, 61, 61, 68, 54,  2, 58]),\n",
       " array([29, 39, 54,  2, 66, 73, 33,  2]),\n",
       " array([ 1, 43, 73, 62, 54,  2, 72, 67]),\n",
       " array([ 1, 33,  2, 72, 67, 73,  2, 68])]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[ys[n][:cs] for n in range(cs)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create and train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hjkim\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(256, activation=\"relu\", kernel_initializer=\"identity\")`\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "dense_in = Dense(n_hidden, activation = 'relu')\n",
    "dense_hidden = Dense(n_hidden, activation = 'relu', init = 'identity')\n",
    "dense_out = Dense(vocab_size, activation = 'softmax', name = 'output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inp1 = Input(shape = (n_fac,), name = 'zero')\n",
    "hidden = dense_in(inp1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hjkim\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  \n",
      "C:\\Users\\hjkim\\Anaconda3\\lib\\site-packages\\keras-2.0.8-py3.6.egg\\keras\\legacy\\layers.py:458: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n"
     ]
    }
   ],
   "source": [
    "outs = []\n",
    "\n",
    "for i in range(cs):\n",
    "    c_dense = dense_in(c_ins[i][1])\n",
    "    hidden = dense_hidden(hidden)\n",
    "    hidden = merge([c_dense, hidden], mode = 'sum')\n",
    "    \n",
    "    # every Layer new has an output\n",
    "    outs.append(dense_out(hidden))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Model([inp1] + [c[0] for c in c_ins], outs)\n",
    "model.compile(loss = 'sparse_categorical_crossentropy', optimizer = Adam())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(75109, 42)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zeros = np.tile(np.zeros(n_fac), (len(xs[0]), 1))\n",
    "zeros.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n",
      "75109/75109 [==============================] - 41s - loss: 20.2048 - output_loss_1: 2.7191 - output_loss_2: 2.5768 - output_loss_3: 2.5206 - output_loss_4: 2.4983 - output_loss_5: 2.4762 - output_loss_6: 2.4806 - output_loss_7: 2.4772 - output_loss_8: 2.4560     - ETA: 50s - loss: 24.1689 - output_loss_1: 3.2838 - output_loss_2: 3.10 - ETA: 27s - loss: 21.9054 - output_loss_1: 2.9263 - output_loss_2: 2.7763 - output_loss_3: 2.7456 - output_loss_4:  - ETA: 17s - loss: 21.1657 - output_loss_1: 2.8284 - output_ - ETA: 7s -\n",
      "Epoch 2/12\n",
      "75109/75109 [==============================] - 37s - loss: 17.8914 - output_loss_1: 2.5146 - output_loss_2: 2.3582 - output_loss_3: 2.2353 - output_loss_4: 2.1827 - output_loss_5: 2.1563 - output_loss_6: 2.1515 - output_loss_7: 2.1605 - output_loss_8: 2.1323     - ETA: 35s - loss: 18.3239 - output_loss_1: 2.5342 - output_loss_2: 2.3648 - output_loss_3: 2.2732 - ou - ETA: 27s - loss: 18.2166 - output_loss_1: 2.5387 - output_loss_2: 2.3639 - output_loss_3: 2.2710 - output_loss_4: 2.2261 - output_loss_5: 2.2128 - output_loss_6: 2.2025  - ETA: 3s - loss: 17.9199 - output_loss_1: 2.5159 - output_loss_2: 2.3594 - output_loss_3: 2.2383 - output_loss_4: 2.1843 - output_loss_5: 2.1613 - output_loss_6 - ETA: 1s - loss: 17.9028 - output_loss_1: 2.5152 - output_loss_2: 2.3587 - output_loss_3: 2.2362 - output_loss_4: 2.1822 - output_loss_5: 2.1595 - output_loss_6: 2.1528 - o\n",
      "Epoch 3/12\n",
      "75109/75109 [==============================] - 37s - loss: 17.2707 - output_loss_1: 2.4982 - output_loss_2: 2.3344 - output_loss_3: 2.1729 - output_loss_4: 2.0920 - output_loss_5: 2.0533 - output_loss_6: 2.0441 - output_loss_7: 2.0499 - output_loss_8: 2.0259     - ETA: 20s - loss: 17.3331 - output_loss_1: 2.4995 - output_loss_2: 2.3348 - output_loss_3: 2.1841 - output_loss_4: 2.0936 - output_loss_5: 2.0521 - output_loss_6: 2.0566 - out\n",
      "Epoch 4/12\n",
      "75109/75109 [==============================] - 37s - loss: 16.8858 - output_loss_1: 2.4919 - output_loss_2: 2.3258 - output_loss_3: 2.1386 - output_loss_4: 2.0371 - output_loss_5: 1.9869 - output_loss_6: 1.9720 - output_loss_7: 1.9780 - output_loss_8: 1.9555    \n",
      "Epoch 5/12\n",
      "75109/75109 [==============================] - 37s - loss: 16.6213 - output_loss_1: 2.4882 - output_loss_2: 2.3202 - output_loss_3: 2.1202 - output_loss_4: 2.0010 - output_loss_5: 1.9404 - output_loss_6: 1.9219 - output_loss_7: 1.9259 - output_loss_8: 1.9035     ETA: 5s - loss: 16.6246 - output_loss_1: 2.4893 - output_loss_2: 2.3158 - output_loss_3: 2.11 - ETA: 1s - loss: 16.6233 - output_loss_1: 2.4892 - output_loss_2: 2.3192 - output_loss_3: 2.1195 - output_loss_4: 2.0027 - output_loss_5: 1.9413 - output_loss_6: 1.\n",
      "Epoch 6/12\n",
      "75109/75109 [==============================] - 37s - loss: 16.4259 - output_loss_1: 2.4864 - output_loss_2: 2.3147 - output_loss_3: 2.1072 - output_loss_4: 1.9749 - output_loss_5: 1.9077 - output_loss_6: 1.8833 - output_loss_7: 1.8875 - output_loss_8: 1.8642    \n",
      "Epoch 7/12\n",
      "75109/75109 [==============================] - 37s - loss: 16.2776 - output_loss_1: 2.4836 - output_loss_2: 2.3136 - output_loss_3: 2.0970 - output_loss_4: 1.9557 - output_loss_5: 1.8822 - output_loss_6: 1.8540 - output_loss_7: 1.8585 - output_loss_8: 1.8329    \n",
      "Epoch 8/12\n",
      "75109/75109 [==============================] - 37s - loss: 16.1587 - output_loss_1: 2.4824 - output_loss_2: 2.3112 - output_loss_3: 2.0892 - output_loss_4: 1.9414 - output_loss_5: 1.8614 - output_loss_6: 1.8301 - output_loss_7: 1.8337 - output_loss_8: 1.8093     ETA: 2s - loss: 16.1500 - output_loss_1: 2.4804 - output_loss_2: 2.3099 - output_loss_3: 2.0867 - output_loss_4: 1.9413 - output_loss_5: 1.86\n",
      "Epoch 9/12\n",
      "75109/75109 [==============================] - 37s - loss: 16.0653 - output_loss_1: 2.4812 - output_loss_2: 2.3098 - output_loss_3: 2.0839 - output_loss_4: 1.9300 - output_loss_5: 1.8453 - output_loss_6: 1.8109 - output_loss_7: 1.8150 - output_loss_8: 1.7892     - ETA: 19s - loss: 16.0551 - output_loss_1: 2.4855 - output_ - ETA: 2s - loss: 16.0608 - output_loss_1: 2.4813 - output_loss_2: 2.3075 - output_loss_3: 2.0844 - output_loss_4: 1.9279 - outpu\n",
      "Epoch 10/12\n",
      "75109/75109 [==============================] - 37s - loss: 15.9809 - output_loss_1: 2.4804 - output_loss_2: 2.3076 - output_loss_3: 2.0792 - output_loss_4: 1.9205 - output_loss_5: 1.8308 - output_loss_6: 1.7950 - output_loss_7: 1.7966 - output_loss_8: 1.7707     ETA: 0s - loss: 15.9809 - output_loss_1: 2.4801 - output_loss_2: 2.3073 - output_loss_3: 2.0798 - output_loss_4: 1.9192 - output_loss_5: 1.8312 - output_loss_6: 1.7949 - output_loss_7: 1.7976 - output_loss\n",
      "Epoch 11/12\n",
      "75109/75109 [==============================] - 37s - loss: 15.9154 - output_loss_1: 2.4794 - output_loss_2: 2.3058 - output_loss_3: 2.0754 - output_loss_4: 1.9135 - output_loss_5: 1.8204 - output_loss_6: 1.7822 - output_loss_7: 1.7820 - output_loss_8: 1.7568    \n",
      "Epoch 12/12\n",
      "75109/75109 [==============================] - 37s - loss: 15.8559 - output_loss_1: 2.4791 - output_loss_2: 2.3040 - output_loss_3: 2.0731 - output_loss_4: 1.9061 - output_loss_5: 1.8113 - output_loss_6: 1.7697 - output_loss_7: 1.7694 - output_loss_8: 1.7432    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x18423400>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit([zeros] + xs, ys, batch_size = 64, epochs = 12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_nexts(inp):\n",
    "    idxs = [char_indices[c] for c in inp]\n",
    "    arrs = [np.array(i)[np.newaxis] for i in idxs]\n",
    "    p = model.predict([np.zeros(n_fac)[np.newaxis,:]] + arrs)\n",
    "    print(list(inp))\n",
    "    return [chars[np.argmax(o)] for o in p]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' ', 't', 'h', 'i', 's', ' ', 'i', 's']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['t', 'h', 'e', 't', ' ', 'i', 'n', ' ']"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_nexts(' this is')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' ', 'p', 'a', 'r', 't', ' ', 'o', 'f']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['t', 'o', 'r', 't', 'i', 'o', 'f', ' ']"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_nexts(' part of')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequence model with keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(256, 42, 8, 86)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_hidden, n_fac, cs, vocab_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To convert out previous keras model into a sequence model, simply add the 'return_sequences = True' parameter, and add TimeDistributed() around out dense layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hjkim\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `SimpleRNN` call to the Keras 2 API: `SimpleRNN(256, return_sequences=True, activation=\"relu\", recurrent_initializer=\"identity\")`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Embedding(vocab_size, n_fac, input_length = cs),\n",
    "    SimpleRNN(n_hidden, return_sequences = True, activation = 'relu', inner_init = 'identity'),\n",
    "    TimeDistributed(Dense(vocab_size, activation = 'softmax'))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_5 (Embedding)      (None, 8, 42)             3612      \n",
      "_________________________________________________________________\n",
      "simple_rnn_2 (SimpleRNN)     (None, 8, 256)            76544     \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 8, 86)             22102     \n",
      "=================================================================\n",
      "Total params: 102,258\n",
      "Trainable params: 102,258\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss = 'sparse_categorical_crossentropy', optimizer = Adam())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(75109, 1)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_rnn = np.stack(np.squeeze(xs), axis = 1)\n",
    "y_rnn = np.atleast_3d(np.stack(ys, axis = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((75109, 8), (75109, 8, 1))"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_rnn.shape, y_rnn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "75109/75109 [==============================] - 43s - loss: 2.4394    \n",
      "Epoch 2/8\n",
      "75109/75109 [==============================] - 42s - loss: 2.0027    \n",
      "Epoch 3/8\n",
      "75109/75109 [==============================] - 42s - loss: 1.8846    \n",
      "Epoch 4/8\n",
      "75109/75109 [==============================] - 41s - loss: 1.8228    \n",
      "Epoch 5/8\n",
      "75109/75109 [==============================] - 41s - loss: 1.7845    \n",
      "Epoch 6/8\n",
      "75109/75109 [==============================] - 41s - loss: 1.7583    - ETA: 1s - ETA: 0s - loss: 1.\n",
      "Epoch 7/8\n",
      "75109/75109 [==============================] - 41s - loss: 1.7381    \n",
      "Epoch 8/8\n",
      "75109/75109 [==============================] - 41s - loss: 1.7225    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c5d7588>"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_rnn, y_rnn, batch_size = 64, epochs = 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_nexts_keras(inp):\n",
    "    idxs = [char_indices[c] for c in inp]\n",
    "    arrs = np.array(idxs)[np.newaxis, :]\n",
    "    p = model.predict(arrs)[0]\n",
    "    print(list(p))\n",
    "    return [chars[np.argmax(o)] for o in p]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([  1.3582e-09,   5.9093e-04,   6.5847e-03,   1.1993e-05,   8.8671e-03,   1.3096e-04,\n",
      "         2.9389e-03,   1.2866e-06,   5.9853e-06,   2.6198e-05,   1.6628e-05,   5.1936e-11,\n",
      "         2.0068e-04,   1.9883e-05,   9.5108e-06,   1.4398e-05,   1.2478e-05,   2.3554e-05,\n",
      "         7.1654e-06,   2.8285e-05,   4.9636e-06,   3.8419e-06,   1.6101e-06,   2.8257e-05,\n",
      "         1.5803e-05,   4.5987e-03,   2.7638e-03,   1.8396e-03,   1.0799e-03,   2.8969e-03,\n",
      "         3.0138e-03,   3.6639e-03,   2.3399e-03,   6.5076e-03,   3.0201e-04,   3.5064e-04,\n",
      "         1.7882e-03,   2.2801e-03,   1.7953e-03,   2.3678e-03,   3.0387e-03,   2.3288e-04,\n",
      "         1.2397e-03,   3.0916e-03,   6.0466e-03,   6.8427e-04,   4.7758e-04,   5.4191e-03,\n",
      "         7.1926e-07,   4.7049e-04,   3.5523e-05,   2.9255e-04,   3.7240e-08,   4.4278e-04,\n",
      "         1.4772e-01,   3.9829e-02,   3.3048e-02,   3.0528e-02,   2.5180e-02,   3.2138e-02,\n",
      "         9.9425e-03,   4.6592e-02,   8.0851e-02,   1.5418e-03,   4.7150e-03,   1.8890e-02,\n",
      "         4.0727e-02,   2.2622e-02,   7.7708e-02,   3.6785e-02,   1.6271e-03,   2.2089e-02,\n",
      "         5.3962e-02,   1.2175e-01,   1.5178e-02,   8.4766e-03,   4.6177e-02,   1.8869e-06,\n",
      "         3.3150e-03,   1.3913e-06,   3.5816e-09,   2.3548e-08,   2.4694e-08,   4.9829e-10,\n",
      "         6.5459e-07,   1.6314e-09], dtype=float32), array([  6.8306e-11,   1.4655e-07,   2.7051e-06,   1.3576e-06,   1.3338e-07,   5.4740e-05,\n",
      "         8.9061e-14,   4.4614e-07,   2.2964e-06,   1.9454e-07,   6.8101e-07,   6.3588e-15,\n",
      "         1.9574e-12,   1.6085e-13,   3.0893e-12,   1.4916e-12,   2.6851e-14,   2.0688e-13,\n",
      "         3.3269e-13,   4.7711e-14,   1.7560e-13,   1.6397e-06,   7.2772e-07,   3.0600e-14,\n",
      "         4.4758e-07,   3.6251e-05,   1.3550e-07,   6.1602e-09,   1.4416e-08,   4.9912e-05,\n",
      "         1.7308e-08,   6.4357e-09,   4.4076e-04,   4.1828e-05,   6.6812e-09,   5.2670e-08,\n",
      "         3.7784e-06,   3.7847e-07,   4.9445e-07,   1.8404e-04,   2.6609e-07,   1.6606e-10,\n",
      "         3.3727e-05,   2.8811e-08,   1.8484e-06,   2.3156e-05,   7.6262e-09,   1.7161e-07,\n",
      "         2.7572e-09,   2.6918e-05,   1.8109e-12,   4.8782e-09,   4.2755e-10,   4.9178e-07,\n",
      "         1.7474e-02,   1.8402e-07,   3.5146e-05,   2.1829e-07,   9.6690e-03,   3.2523e-06,\n",
      "         3.5733e-07,   7.7352e-01,   1.0351e-02,   4.6011e-09,   2.1018e-06,   5.3488e-04,\n",
      "         7.2212e-06,   2.9620e-05,   1.5986e-01,   7.5701e-06,   3.6346e-07,   2.0475e-02,\n",
      "         3.8863e-06,   7.6934e-05,   1.1639e-03,   8.8618e-09,   2.2817e-03,   4.3756e-10,\n",
      "         3.5833e-03,   1.5707e-05,   9.6582e-13,   8.4981e-13,   1.6604e-09,   2.3764e-12,\n",
      "         6.8517e-13,   4.4290e-11], dtype=float32), array([  1.6312e-10,   7.0980e-06,   8.2577e-05,   1.5045e-06,   8.2888e-07,   8.9936e-06,\n",
      "         2.8514e-14,   5.7843e-07,   7.3458e-06,   1.1640e-06,   1.7718e-06,   1.8763e-13,\n",
      "         6.7430e-13,   2.8177e-13,   1.4800e-12,   2.3042e-13,   4.6349e-14,   3.3400e-14,\n",
      "         1.7564e-12,   8.4995e-13,   6.1282e-14,   2.4521e-06,   7.4066e-07,   7.2361e-12,\n",
      "         2.0223e-06,   7.2972e-05,   1.7865e-08,   2.7163e-10,   7.5123e-09,   2.2584e-04,\n",
      "         3.6342e-11,   4.1597e-11,   2.3333e-08,   1.4750e-05,   8.5358e-09,   1.7170e-10,\n",
      "         7.9247e-07,   7.2671e-07,   1.0005e-07,   1.0707e-05,   1.7805e-07,   1.7188e-11,\n",
      "         1.9351e-05,   3.7760e-07,   1.4267e-07,   3.4309e-06,   8.7937e-11,   9.4709e-08,\n",
      "         1.1950e-08,   1.8894e-06,   4.6305e-10,   1.3197e-10,   8.5957e-10,   4.4237e-07,\n",
      "         1.8769e-01,   4.0348e-07,   1.0248e-06,   9.5190e-08,   6.9115e-01,   4.5695e-08,\n",
      "         4.7559e-07,   2.3032e-06,   8.0522e-02,   1.1840e-08,   2.5392e-07,   2.5769e-04,\n",
      "         1.8679e-04,   2.6925e-05,   2.1696e-02,   6.6973e-06,   2.0271e-08,   1.1167e-02,\n",
      "         2.5926e-05,   1.1751e-05,   6.1113e-03,   1.7987e-09,   2.1125e-05,   2.1197e-09,\n",
      "         6.5491e-04,   3.3755e-07,   4.3772e-09,   2.3387e-11,   1.2824e-08,   2.0431e-12,\n",
      "         1.9474e-10,   3.5563e-11], dtype=float32), array([  1.7615e-11,   9.1838e-07,   1.9863e-06,   2.1468e-08,   5.4173e-08,   5.5911e-09,\n",
      "         2.7896e-15,   9.8985e-07,   6.7972e-07,   7.2195e-07,   2.2927e-07,   9.1492e-15,\n",
      "         2.1965e-09,   3.7614e-10,   1.2034e-12,   2.7053e-12,   2.0670e-13,   5.7657e-13,\n",
      "         8.7730e-13,   9.2382e-12,   2.1385e-13,   6.6863e-08,   1.2223e-07,   2.7700e-18,\n",
      "         2.4583e-07,   6.7919e-09,   6.7732e-10,   1.2763e-07,   2.0952e-09,   3.3078e-09,\n",
      "         1.0839e-10,   3.5970e-08,   6.1721e-11,   1.1365e-09,   9.0934e-10,   1.0290e-13,\n",
      "         8.2768e-09,   1.3098e-08,   2.5782e-07,   3.5643e-10,   4.4504e-09,   5.0473e-14,\n",
      "         6.7047e-07,   1.1773e-05,   3.6205e-08,   1.9365e-10,   1.5519e-10,   1.9437e-10,\n",
      "         2.3662e-10,   1.2735e-12,   1.5646e-09,   2.1166e-11,   9.9126e-10,   2.7053e-07,\n",
      "         1.2399e-04,   2.1319e-06,   2.6134e-03,   2.8651e-05,   2.9190e-03,   4.0539e-04,\n",
      "         7.7462e-04,   1.4727e-04,   1.9641e-05,   1.1697e-07,   1.9612e-06,   8.5062e-04,\n",
      "         2.3940e-03,   5.7044e-01,   1.7409e-03,   3.3051e-06,   1.2327e-07,   3.0984e-03,\n",
      "         4.0355e-01,   8.9542e-03,   1.6130e-03,   2.8343e-04,   5.6779e-07,   4.4898e-06,\n",
      "         3.1502e-08,   9.1829e-06,   2.1652e-12,   2.9108e-13,   8.9768e-12,   9.9330e-13,\n",
      "         6.7608e-14,   9.1467e-12], dtype=float32), array([  1.0542e-10,   1.0029e-01,   8.4459e-01,   7.6483e-04,   1.2309e-03,   5.3185e-06,\n",
      "         2.0369e-11,   2.2916e-04,   2.8244e-02,   1.2720e-03,   3.9299e-03,   1.4365e-12,\n",
      "         3.7800e-12,   4.8845e-13,   4.8233e-12,   1.5671e-12,   1.0652e-13,   9.5029e-13,\n",
      "         3.1138e-12,   4.7658e-13,   6.5595e-13,   1.0008e-03,   2.4842e-03,   8.0246e-11,\n",
      "         3.4474e-04,   3.0577e-08,   1.5022e-10,   4.5919e-09,   4.5567e-11,   1.3048e-09,\n",
      "         1.8040e-10,   3.3684e-10,   1.0481e-07,   3.9974e-09,   6.8636e-12,   1.6182e-11,\n",
      "         1.2025e-08,   7.7747e-09,   2.0863e-09,   9.4905e-11,   8.5816e-10,   4.4191e-10,\n",
      "         2.3488e-11,   2.2622e-09,   1.8900e-07,   5.4156e-10,   5.1520e-11,   9.3735e-10,\n",
      "         3.7484e-10,   9.1737e-13,   8.7215e-11,   6.1030e-08,   6.0150e-05,   6.2249e-06,\n",
      "         7.2487e-04,   6.9444e-06,   3.2928e-05,   7.2617e-06,   1.2234e-03,   3.7598e-03,\n",
      "         9.0656e-05,   1.7535e-03,   5.3639e-04,   1.8803e-07,   3.1306e-03,   3.4993e-05,\n",
      "         1.3834e-03,   8.3051e-05,   3.0536e-04,   1.2005e-05,   6.8202e-06,   9.5858e-08,\n",
      "         6.7393e-04,   1.6270e-03,   6.3613e-05,   4.4177e-05,   2.2121e-05,   5.0828e-08,\n",
      "         1.5874e-05,   3.8337e-07,   5.6095e-10,   4.0299e-10,   5.8291e-09,   4.6906e-11,\n",
      "         2.2905e-11,   2.4477e-09], dtype=float32), array([  1.0415e-07,   7.3721e-05,   4.4811e-05,   3.6549e-05,   8.7430e-03,   2.3985e-04,\n",
      "         2.2677e-03,   1.0624e-05,   1.3382e-05,   1.9129e-04,   5.4901e-06,   3.3512e-09,\n",
      "         3.3056e-05,   1.2930e-05,   4.5045e-06,   7.4926e-06,   2.1016e-05,   7.8412e-06,\n",
      "         2.0409e-06,   1.6577e-05,   1.8416e-06,   7.1650e-05,   1.2654e-05,   9.9729e-06,\n",
      "         6.0159e-05,   9.1255e-04,   1.0400e-03,   4.9792e-03,   1.0148e-03,   1.8674e-03,\n",
      "         1.2185e-03,   2.4819e-03,   4.6418e-04,   1.5857e-03,   6.5806e-04,   2.1188e-04,\n",
      "         6.5899e-04,   1.8816e-03,   1.2809e-03,   4.6015e-04,   2.3612e-03,   1.1189e-04,\n",
      "         1.5525e-03,   2.2515e-03,   9.5666e-04,   2.9796e-04,   4.6433e-04,   1.8480e-03,\n",
      "         1.4740e-06,   1.0363e-04,   1.6826e-04,   1.1380e-03,   1.8506e-07,   1.3059e-03,\n",
      "         7.5239e-02,   2.3399e-02,   5.6479e-02,   5.7781e-02,   2.9775e-02,   4.5942e-02,\n",
      "         1.3102e-02,   3.8262e-02,   8.9625e-02,   3.3272e-03,   6.4219e-03,   2.7842e-02,\n",
      "         5.4114e-02,   3.1179e-02,   4.1826e-02,   8.6020e-02,   2.8288e-03,   2.7291e-02,\n",
      "         1.0266e-01,   4.7676e-02,   1.0487e-02,   3.2566e-02,   5.0115e-02,   2.1336e-05,\n",
      "         5.2459e-04,   3.1832e-04,   1.2047e-07,   8.8353e-06,   1.9599e-08,   1.1551e-07,\n",
      "         4.8051e-06,   1.3610e-07], dtype=float32), array([  1.1347e-10,   1.4147e-05,   6.3608e-04,   6.7038e-07,   5.8463e-07,   1.6099e-07,\n",
      "         7.5057e-12,   1.4172e-06,   2.4315e-05,   8.1749e-06,   2.9546e-06,   2.8016e-13,\n",
      "         6.7295e-08,   1.7603e-09,   6.0297e-10,   2.1147e-10,   1.3908e-10,   1.1001e-10,\n",
      "         2.4951e-11,   4.3852e-10,   2.5365e-10,   4.0085e-07,   4.0989e-07,   8.5306e-15,\n",
      "         2.1679e-06,   7.4100e-09,   4.2984e-08,   2.2309e-07,   1.5047e-08,   3.4124e-08,\n",
      "         1.2045e-07,   1.0510e-07,   3.0365e-11,   7.1304e-10,   5.0524e-12,   8.9369e-14,\n",
      "         3.1190e-09,   1.8651e-07,   6.3887e-06,   2.9509e-08,   2.3367e-08,   1.2228e-12,\n",
      "         2.7328e-08,   1.2673e-06,   1.4548e-08,   2.7189e-08,   2.3161e-08,   3.3160e-08,\n",
      "         3.2580e-09,   1.3521e-12,   5.8068e-11,   3.2103e-09,   4.4452e-11,   4.2627e-06,\n",
      "         4.1061e-03,   2.0713e-04,   7.7054e-04,   5.4957e-02,   3.0419e-04,   5.7591e-03,\n",
      "         3.9083e-03,   2.0741e-04,   1.2000e-06,   1.4620e-06,   2.0994e-04,   3.7105e-03,\n",
      "         7.4761e-02,   4.5687e-01,   2.1575e-04,   2.1507e-03,   1.0893e-05,   3.2258e-03,\n",
      "         3.3818e-01,   4.8610e-02,   5.3391e-04,   4.1436e-04,   4.3121e-05,   3.2560e-05,\n",
      "         3.1984e-07,   1.0034e-04,   4.7166e-13,   2.8314e-13,   7.7173e-10,   1.2085e-11,\n",
      "         2.6184e-13,   2.4702e-11], dtype=float32), array([  2.2289e-08,   4.3476e-02,   8.1758e-01,   1.9314e-03,   5.9431e-04,   5.0637e-07,\n",
      "         1.0309e-09,   7.0213e-04,   6.5213e-02,   5.5234e-03,   1.1454e-02,   1.6199e-10,\n",
      "         2.2720e-10,   4.3740e-11,   8.5481e-11,   3.7809e-11,   1.7225e-12,   2.9114e-11,\n",
      "         2.7632e-11,   4.3837e-11,   1.3036e-10,   4.4192e-03,   4.9210e-03,   3.6609e-08,\n",
      "         6.3426e-04,   6.6770e-07,   4.1039e-08,   5.2045e-08,   1.1552e-08,   3.2735e-07,\n",
      "         2.1445e-07,   3.4949e-09,   6.3547e-07,   6.8976e-07,   7.7986e-09,   5.2082e-09,\n",
      "         1.0251e-06,   3.5154e-06,   1.0350e-06,   4.8066e-08,   3.1018e-06,   6.7346e-08,\n",
      "         3.0336e-09,   1.1350e-05,   1.0468e-05,   7.4118e-08,   2.2803e-09,   3.9605e-07,\n",
      "         2.7148e-08,   4.8680e-09,   3.4546e-09,   7.2619e-06,   9.8101e-04,   6.6202e-05,\n",
      "         9.7493e-04,   6.4616e-05,   1.3739e-03,   1.4404e-05,   6.4332e-03,   1.0937e-03,\n",
      "         3.8980e-06,   9.8212e-04,   2.0185e-03,   2.0299e-06,   7.5710e-06,   6.6723e-04,\n",
      "         1.5171e-02,   3.6362e-04,   1.4270e-03,   1.1206e-03,   2.6644e-05,   2.6883e-05,\n",
      "         7.4893e-03,   2.2485e-03,   5.3147e-04,   3.5232e-05,   3.6330e-04,   1.3381e-06,\n",
      "         2.0497e-05,   7.4276e-07,   1.8503e-08,   1.1909e-08,   1.8658e-07,   4.1334e-09,\n",
      "         2.4761e-09,   2.2555e-08], dtype=float32)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['a', 'h', 'e', 'n', ' ', 's', 'n', ' ']"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_nexts_keras(' this is')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### one-hot sequence model with keras\n",
    "\n",
    "This is the keras version of th theano model taht we're about to create."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hjkim\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: UserWarning: Update your `SimpleRNN` call to the Keras 2 API: `SimpleRNN(256, return_sequences=True, input_shape=(8, 86), activation=\"relu\", recurrent_initializer=\"identity\")`\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    SimpleRNN(n_hidden, return_sequences = True, input_shape = (cs, vocab_size), activation = 'relu', inner_init = 'identity'),\n",
    "    TimeDistributed(Dense(vocab_size, activation = 'softmax'))\n",
    "])\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer = Adam())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((75109, 8, 86), (75109, 8, 86))"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oh_ys = [to_categorical(o, vocab_size) for o in ys]\n",
    "oh_y_rnn = np.stack(oh_ys, axis = 1)\n",
    "\n",
    "oh_xs = [to_categorical(o, vocab_size) for o in xs]\n",
    "oh_x_rnn = np.stack(oh_xs, axis = 1)\n",
    "\n",
    "oh_x_rnn.shape, oh_y_rnn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "75109/75109 [==============================] - 47s - loss: 2.4419    \n",
      "Epoch 2/8\n",
      "75109/75109 [==============================] - 46s - loss: 2.0369    \n",
      "Epoch 3/8\n",
      "75109/75109 [==============================] - 45s - loss: 1.9218    \n",
      "Epoch 4/8\n",
      "75109/75109 [==============================] - 45s - loss: 1.8569    \n",
      "Epoch 5/8\n",
      "75109/75109 [==============================] - 46s - loss: 1.8136    \n",
      "Epoch 6/8\n",
      "75109/75109 [==============================] - 46s - loss: 1.7829    \n",
      "Epoch 7/8\n",
      "75109/75109 [==============================] - 45s - loss: 1.7588    \n",
      "Epoch 8/8\n",
      "75109/75109 [==============================] - 49s - loss: 1.7407    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1cc5b470>"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(oh_x_rnn, oh_y_rnn, batch_size = 64, epochs = 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_nexts_oh(inp):\n",
    "    idxs = np.array([char_indices[c] for c in inp])\n",
    "    arr = to_categorical(idxs, vocab_size)\n",
    "    \n",
    "    p = model.predict(arr[np.newaxis, :])[0]\n",
    "    print(list(inp))\n",
    "    return [chars[np.argmax(o)] for o in p]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' ', 't', 'h', 'i', 's', ' ', 'i', 's']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['t', 'h', 'e', 's', ' ', 'c', 's', ' ']"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_nexts_oh(' this is')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Stateful model with keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bs = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A stateful model is easy to create (just add \"stateful=True\") but harder to train. We had to add batchnorm and use LSTM to get resonable results. When Using stateful in keras, you have to also add 'batch_input_shape' to the first layer, and the catch size there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Embedding(vocab_size , n_fac, input_length = cs, batch_input_shape = (bs, 8)),\n",
    "    BatchNormalization(),\n",
    "    LSTM(n_hidden, return_sequences = True, stateful = True),\n",
    "    TimeDistributed(Dense(vocab_size, activation = 'softmax'))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss = 'sparse_categorical_crossentropy', optimizer = Adam())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we're using a fixed batch shape, we have to ensure our inputs and outputs are even multiple of the batch size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mx = len(x_rnn) // bs * bs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "75072/75072 [==============================] - 109s - loss: 2.2803   \n",
      "Epoch 2/4\n",
      "75072/75072 [==============================] - 103s - loss: 2.0288   \n",
      "Epoch 3/4\n",
      "75072/75072 [==============================] - 102s - loss: 1.9552   \n",
      "Epoch 4/4\n",
      "75072/75072 [==============================] - 104s - loss: 1.9143   \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x525c9940>"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_rnn[:mx], y_rnn[:mx], batch_size = bs, epochs = 4, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.optimizer.lr = 1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "75072/75072 [==============================] - 104s - loss: 1.8864   \n",
      "Epoch 2/4\n",
      "75072/75072 [==============================] - 103s - loss: 1.8650   \n",
      "Epoch 3/4\n",
      "75072/75072 [==============================] - 104s - loss: 1.8479   \n",
      "Epoch 4/4\n",
      "75072/75072 [==============================] - 102s - loss: 1.8340   \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c6ebcc0>"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_rnn[:mx], y_rnn[:mx], batch_size = bs, epochs = 4, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "75072/75072 [==============================] - 104s - loss: 1.8224   \n",
      "Epoch 2/4\n",
      "75072/75072 [==============================] - 107s - loss: 1.8125   \n",
      "Epoch 3/4\n",
      "75072/75072 [==============================] - 102s - loss: 1.8040   \n",
      "Epoch 4/4\n",
      "75072/75072 [==============================] - 102s - loss: 1.7963   \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x51e1d7b8>"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_rnn[:mx], y_rnn[:mx], batch_size = bs, epochs = 4, shuffle = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Theano RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_input = vocab_size\n",
    "n_output = vocab_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using raw theano, we have to create out wieght matrices and bias vectors ourselves - here are the functions we'll use to do so (using florot initialiation). The return values are wrapped in shared(), whicih is how we thell theano that it ca manage this data (copying it to and from the GPU as necessary)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def init_wgts(rows, cols):\n",
    "    scale = math.sqrt(2. / rows)\n",
    "    return shared(normal(scale = scale, size = (rows, cols)).astype(np.float32))\n",
    "\n",
    "def init_bias(rows):\n",
    "    return shared(np.zeros(rows, dtype = np.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We return the weights and biases together as a tuple. For the hidden weights, we'll use an identity intialization (as recommended by [Hinton]().)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def wgts_and_bias(n_in, n_out):\n",
    "    return init_wgts(n_in, n_out), init_bias(n_out)\n",
    "\n",
    "def id_and_bias(n):\n",
    "    return shared(np.eye(n, dtype = np.float32)), init_bias(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Theano doesn;t actually do any computations until we explicitly compile and evaluate the function (at which point it'll be turned into CUDA code and sent off to the GPU). SO or job is to describe the computations that we;ll wnat theano to do - the first step is to tell theano what inputs we'll be providing to our computation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_inp = T.matrix('inp')\n",
    "t_outp = T.matrix('outp')\n",
    "t_h0 = T.vector('h0')\n",
    "lr = T.scalar('lr')\n",
    "\n",
    "all_args = [t_h0, t_inp, t_outp, lr]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we're ready to create out initial weight matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "W_h = id_and_bias(n_hidden)\n",
    "W_x = wgts_and_bias(n_input, n_hidden)\n",
    "W_y = wgts_and_bias(n_hidden, n_output)\n",
    "w_all = list(chain.from_iterable([W_h, W_x, W_y]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Theano handles looping by using the [GPU scan]() operation. We have to tell theano what to do at each step through the scan - this is the function we'll use, which does a single forward pass for one character:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def step(x, h, W_h, b_h, W_x, b_x, W_y, b_y):\n",
    "    # Calculate the hidden activations\n",
    "    h = nnet.relu(T.dot(x, W_x) + b_x + T.dot(h, W_h) + b_h)\n",
    "    # Calculate the output activations\n",
    "    y = nnet.softmax(T.dot(h, W_y) + b_y)\n",
    "    # Return both (the 'Flatten()' is to work around a theano bug)\n",
    "    return h, T.flatten(y, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can provide everything necessary for the scan operation, so we can setup that up - we have to pass inthe function to call at each step, the sequence to step through, the intital values of the outputs, and any other arguments to pass to the step function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "[v_h, v_y], _ = theano.scan(step, sequences = t_inp, outputs_info = [t_h0, None], non_sequences = w_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now calculate our loss function, and *all* of our gradients, with just a couple of lines of code!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "error = nnet.categorical_crossentropy(v_y, t_outp).sum()\n",
    "g_all = T.grad(error, w_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We even have to show theano show to how to do SGD - so we setup this dictionary of updates to complete after every forward pass, which apply to standard SGD update rule to every weight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upd_dict(wgts, grads, lr):\n",
    "    return OrderedDict({w: w-g*lr for (w, g) in zip(wgts, grads) })\n",
    "\n",
    "upd = upd_dict(w_all, g_all, lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're finally ready to compile the function!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "('An update must have the same type as the original shared variable (shared_var=<TensorType(float32, matrix)>, shared_var.type=TensorType(float32, matrix), update_val=Elemwise{sub,no_inplace}.0, update_val.type=TensorType(float64, matrix)).', 'If the difference is related to the broadcast pattern, you can call the tensor.unbroadcast(var, axis_to_unbroadcast[, ...]) function to remove broadcastable dimensions.')",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\hjkim\\Anaconda3\\lib\\site-packages\\theano\\compile\\pfunc.py\u001b[0m in \u001b[0;36mrebuild_collect_shared\u001b[1;34m(outputs, inputs, replace, updates, rebuild_strict, copy_inputs_over, no_default_updates)\u001b[0m\n\u001b[0;32m    192\u001b[0m             update_val = store_into.type.filter_variable(update_val,\n\u001b[1;32m--> 193\u001b[1;33m                                                          allow_convert=False)\n\u001b[0m\u001b[0;32m    194\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\hjkim\\Anaconda3\\lib\\site-packages\\theano\\tensor\\type.py\u001b[0m in \u001b[0;36mfilter_variable\u001b[1;34m(self, other, allow_convert)\u001b[0m\n\u001b[0;32m    234\u001b[0m                  \u001b[0mother\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 235\u001b[1;33m                  self=self))\n\u001b[0m\u001b[0;32m    236\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Cannot convert Type TensorType(float64, matrix) (of Variable Elemwise{sub,no_inplace}.0) into Type TensorType(float32, matrix). You can try to manually convert Elemwise{sub,no_inplace}.0 into a TensorType(float32, matrix).",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-144-4113b5587147>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mfn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtheano\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merror\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mupdates\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mupd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_input_downcast\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Users\\hjkim\\Anaconda3\\lib\\site-packages\\theano\\compile\\function.py\u001b[0m in \u001b[0;36mfunction\u001b[1;34m(inputs, outputs, mode, updates, givens, no_default_updates, accept_inplace, name, rebuild_strict, allow_input_downcast, profile, on_unused_input)\u001b[0m\n\u001b[0;32m    324\u001b[0m                    \u001b[0mon_unused_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mon_unused_input\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    325\u001b[0m                    \u001b[0mprofile\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mprofile\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 326\u001b[1;33m                    output_keys=output_keys)\n\u001b[0m\u001b[0;32m    327\u001b[0m     \u001b[1;31m# We need to add the flag check_aliased inputs if we have any mutable or\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    328\u001b[0m     \u001b[1;31m# borrowed used defined inputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\hjkim\\Anaconda3\\lib\\site-packages\\theano\\compile\\pfunc.py\u001b[0m in \u001b[0;36mpfunc\u001b[1;34m(params, outputs, mode, updates, givens, no_default_updates, accept_inplace, name, rebuild_strict, allow_input_downcast, profile, on_unused_input, output_keys)\u001b[0m\n\u001b[0;32m    447\u001b[0m                                          \u001b[0mrebuild_strict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrebuild_strict\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    448\u001b[0m                                          \u001b[0mcopy_inputs_over\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 449\u001b[1;33m                                          no_default_updates=no_default_updates)\n\u001b[0m\u001b[0;32m    450\u001b[0m     \u001b[1;31m# extracting the arguments\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    451\u001b[0m     \u001b[0minput_variables\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcloned_extended_outputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother_stuff\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moutput_vars\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\hjkim\\Anaconda3\\lib\\site-packages\\theano\\compile\\pfunc.py\u001b[0m in \u001b[0;36mrebuild_collect_shared\u001b[1;34m(outputs, inputs, replace, updates, rebuild_strict, copy_inputs_over, no_default_updates)\u001b[0m\n\u001b[0;32m    206\u001b[0m                        ' function to remove broadcastable dimensions.')\n\u001b[0;32m    207\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 208\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merr_msg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merr_sug\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    209\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mupdate_val\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mstore_into\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: ('An update must have the same type as the original shared variable (shared_var=<TensorType(float32, matrix)>, shared_var.type=TensorType(float32, matrix), update_val=Elemwise{sub,no_inplace}.0, update_val.type=TensorType(float64, matrix)).', 'If the difference is related to the broadcast pattern, you can call the tensor.unbroadcast(var, axis_to_unbroadcast[, ...]) function to remove broadcastable dimensions.')"
     ]
    }
   ],
   "source": [
    "fn = theano.function(all_args, error, updates = upd, allow_input_downcast = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pure python RNN\n",
    "\n",
    "### SEtup basic functions\n",
    "\n",
    "Now we're going to try to repeat the above theano RNN, using just python (and numpy). Which means, we have to do everything ourselves, including defining the basic functions of a neural net! Below are all of the definitions, along with tests to check tat they give the same answers as theano. The functions ending in \\_d are the defivatives of each function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sigmoid(x) : return 1 / (1 + np.exp(-x))\n",
    "def sigmoid_d(x):\n",
    "    output = sigmoid(x)\n",
    "    return output * (1 - output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def relu(x): return np.maximum(0., x)\n",
    "def relu_d(x): return (x > 0.) * 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 3.,  0.]), array([ 1.,  0.]))"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relu(np.array([3.,-3.])), relu_d(np.array([3., -3.]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dist(a, b): return pow(a-b,2)\n",
    "def dist_d(a,b): return 2*(a-b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "esp = 1e-7\n",
    "def x_entropy(pred, actual):\n",
    "    return -np.sum(actual * np.log(np.clip(pred, esp, 1-esp)))\n",
    "def x_entropy_d(pred, actual): return -actual / pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def softmax(x): return np.exp(x) / np.exp(x).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def softmax_d(x):\n",
    "    sm = softmax(x)\n",
    "    res = np.expand_dims(-sm, -1) * sm\n",
    "    res[np.diag_indices_from(res)] = sm*(1-sm)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(0.35667494393873245)"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_preds = np.array([0.2, 0.7, 0.1])\n",
    "test_actuals = np.array([0., 1., 0.])\n",
    "nnet.categorical_crossentropy(test_preds, test_actuals).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.35667494393873245"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_entropy(test_preds, test_actuals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_inp = T.dvector()\n",
    "test_out = nnet.categorical_crossentropy(test_inp, test_actuals)\n",
    "test_grad = theano.function([test_inp], T.grad(test_out, test_inp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.    , -1.4286, -0.    ])"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_grad(test_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.    , -1.4286, -0.    ])"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_entropy_d(test_preds, test_actuals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_pred = random(oh_x_rnn[0][0].shape)\n",
    "preds = softmax(pre_pred)\n",
    "actual = oh_x_rnn[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.allclose(softmax_d(pre_pred).dot(x_entropy_d(preds, actual)), preds - actual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.2814,  0.464 ,  0.2546])"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax(test_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.2814,  0.464 ,  0.2546]])"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nnet.softmax(test_preds).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_out = T.flatten(nnet.softmax(test_inp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_grad = theano.function([test_inp], theano.gradient.jacobian(test_out, test_inp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.2022, -0.1306, -0.0717],\n",
       "       [-0.1306,  0.2487, -0.1181],\n",
       "       [-0.0717, -0.1181,  0.1898]])"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_grad(test_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.2022, -0.1306, -0.0717],\n",
       "       [-0.1306,  0.2487, -0.1181],\n",
       "       [-0.0717, -0.1181,  0.1898]])"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax_d(test_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "act = relu\n",
    "act_d = relu_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss = x_entropy\n",
    "loss_d = x_entropy_d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also have to define out own scan function. Since we're not worrying about running things in parallel. Its's very simple to implement:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def scan(fn, start, seq):\n",
    "    res = []\n",
    "    prev = start\n",
    "    for s in seq:\n",
    "        app = fn(prev, s)\n",
    "        res.append(app)\n",
    "        prev = app\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For instance, scan on + is the cumulative sum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 3, 6, 10]"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scan(lambda prev, curr: prev+curr, 0, range(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up training\n",
    "\n",
    "Let's now build the functions to do the forward and backward passes of out RNN, First, define our data and shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inp = oh_x_rnn\n",
    "outp = oh_y_rnn\n",
    "n_input = vocab_size\n",
    "n_output = vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((75109, 8, 86), (75109, 8, 86))"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp.shape, outp.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's the functioni to do a single forward pass of an RNN, for a single character."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_char(prev, item):\n",
    "    # previous state\n",
    "    tot_loss, pre_hidden, pre_pred, hidden, ypred = prev\n",
    "    # current tinputs and output\n",
    "    x, y = item\n",
    "    pre_hidden = np.dot(x, w_x) + np.dot(hidden, w_h)\n",
    "    hidden = act(pre_hidden)\n",
    "    pre_pred = np.dot(hidden, w_y)\n",
    "    ypred = softmax(pre_pred)\n",
    "    return (\n",
    "    # keep track of loss so we can report it\n",
    "    tot_loss + loss(ypred, y),\n",
    "    # used in backprop\n",
    "    pre_hidden, pre_pred,\n",
    "    # used in next iteration\n",
    "    hidden,\n",
    "    # to provide predictions\n",
    "    ypred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use scan to apply the above to a whole sequence of characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_chars(n): return zip(inp[n], outp[n])\n",
    "def one_fwd(n): return scan(one_char, (0,0,0,np.zeros(n_hidden), 0), get_chars(n))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can define the cbackward step. We use a loop to fo through every element of the sequence. The derivatives are applying the chain rule to each step, and accumulating the gradients across the sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "# columnify a vector\n",
    "def col(x): return x[:, newaxis]\n",
    "\n",
    "def one_bkwd(args, n):\n",
    "    global w_x, w_y, w_h\n",
    "    \n",
    "    i = inp[n]  # 8x86\n",
    "    o = outp[n]  # 8x86\n",
    "    d_pre_hidden = np.zeros(n_hidden) # 256\n",
    "    \n",
    "    for p in reversed(range(len(i))):\n",
    "        totloss, pre_hidden, pre_pred, hidden, ypred = args[p]\n",
    "        x = i[p] # 86\n",
    "        y = o[p] # 86\n",
    "        d_pre_pred = softmax_d(pre_pred).dot(loss_d(ypred, y)) # 86\n",
    "        d_pre_hidden = (np.dot(d_pre_hidden, w_h.T) + np.dot(d_pre_pred, w_y.T)) * act_d(pre_hidden) # 256\n",
    "        \n",
    "        # d(loss)/d(w_y) = d(loss)/d(pre_pred) * d(pre_pred)/d(w_y)\n",
    "        w_y -= col(hidden) * d_pre_pred * alpha\n",
    "        # d(loss)/d(w_h) = d(loss)/d(pre_hidden[p-1]) * d(pre_hidden[p-1])/d(w_h)\n",
    "        if (p > 0): w_h -= args[p-1][3].dot(d_pre_hidden) * alpha\n",
    "        w_x -= col(x) * d_pre_hidden * alpha\n",
    "    return d_pre_hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can set up our initial weight matrices. Note that we're not using bisa at all in this example, in order to keep things simpler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scale = math.sqrt(2. / n_input)\n",
    "w_x = normal(scale = scale, size = (n_input, n_hidden))\n",
    "w_y = normal(scale = scale, size = (n_hidden, n_output))\n",
    "w_h = np.eye(n_hidden, dtype = np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Out loop looks much like the theano loop in the previous section, except hat we have to call the backwards step ourselves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error:35.8657; Gradient:2.68377\n",
      "Error:35.6886; Gradient:2.13522\n",
      "Error:35.6671; Gradient:2.22855\n",
      "Error:35.6236; Gradient:2.20996\n",
      "Error:35.5871; Gradient:1.96299\n",
      "Error:35.5815; Gradient:1.98897\n",
      "Error:35.5323; Gradient:1.75088\n",
      "Error:35.5286; Gradient:1.93306\n",
      "Error:35.5256; Gradient:1.85797\n",
      "Error:35.4930; Gradient:2.06328\n"
     ]
    }
   ],
   "source": [
    "overallError = 0\n",
    "alpha = 1e-5\n",
    "for n in range(10000):\n",
    "    res = one_fwd(n)\n",
    "    overallError += res[-1][0]\n",
    "    deriv = one_bkwd(res, n)\n",
    "    if (n % 1000 == 999):\n",
    "        print(\"Error:{:.4f}; Gradient:{:.5f}\".format(overallError/1000, np.linalg.norm(deriv)))\n",
    "        overallError = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras GRU\n",
    "\n",
    "Identical to the last keras mn, but a GRU!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    GRU(n_hidden, return_sequences = True, input_shape = (cs, vocab_size), activation = 'relu'),\n",
    "    TimeDistributed(Dense(vocab_size, activation = 'softmax'))\n",
    "])\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer = Adam())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "75109/75109 [==============================] - 89s - loss: 2.3978    \n",
      "Epoch 2/8\n",
      "75109/75109 [==============================] - 84s - loss: 1.9885    \n",
      "Epoch 3/8\n",
      "75109/75109 [==============================] - 84s - loss: 1.8749    \n",
      "Epoch 4/8\n",
      "75109/75109 [==============================] - 84s - loss: 1.8121    \n",
      "Epoch 5/8\n",
      "75109/75109 [==============================] - 84s - loss: 1.7696    \n",
      "Epoch 6/8\n",
      "75109/75109 [==============================] - 88s - loss: 1.7387    \n",
      "Epoch 7/8\n",
      "75109/75109 [==============================] - 90s - loss: 1.7153    \n",
      "Epoch 8/8\n",
      "75109/75109 [==============================] - 88s - loss: 1.6949    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x5de99e80>"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(oh_x_rnn, oh_y_rnn, batch_size = 64, epochs = 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' ', 't', 'h', 'i', 's', ' ', 'i', 's']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['t', 'h', 'e', 's', ' ', 'c', 'n', ' ']"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_nexts_oh(' this is')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Theano GRU\n",
    "\n",
    "### Separate weights\n",
    "\n",
    "The theano GRU looks just like the simple theano RNN, except for the use of the reset and update gates. Each of these gates requires its own hidden and input weights, so we add those to our weight matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W_h = id_and_bias(n_hidden)\n",
    "W_x = init_wgts(n_input, n_hidden)\n",
    "W_y = wgts_and_bias(n_hidden, n_output)\n",
    "rW_h = init_wgts(n_hidden, n_hidden)\n",
    "rW_x = wgts_and_bias(n_input, n_hidden)\n",
    "uW_h = init_wgts(n_hidden, n_hidden)\n",
    "uW_x = wgts_and_bias(n_input, n_hidden)\n",
    "w_all = list(chain.from_iterable([W_h, W_y, uW_x, rW_x]))\n",
    "w_all.extend([W_x, uW_h, rW_h])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's the definition of a gate - it's just a sigmoid applied to the addition of the dot prodicts of th einput vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gate(x, h, W_h, W_x, b_x):\n",
    "    return nnet.sigmoid(T.dot(x, W_x) + b_x + T.dot(h, W_h))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our step is nearly identical to before, except that we multiply our hidden state by our reset gate, adn we update our hiden state based on the update gate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def step(x, h, W_h, b_h, W_y, b_y, uW_x, ub_x, rW_x, rb_x, W_x, uW_h, rW_h):\n",
    "    reset = gate(x, h, rW_h, rW_x, rb_x)\n",
    "    update = gate(x, h, uW_h, uW_x, ub_x)\n",
    "    h_new = gate(x, h * reset, W_h, W_x, b_h)\n",
    "    h = update * h + (1.0 - update) * h_new\n",
    "    y = nnet.softmax(T.dot(h, W_y) + b_y)\n",
    "    return h, T.flatten(y, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Everything from here on is identical to our simple RNN in thano."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "[v_h, v_y,], _ = theano.scan(step, sequences = t_inp, outputs_info = [t_h0, None], non_sequences = w_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "error = nnet.categorical_crossentropy(v_y, t_outp).sum()\n",
    "g_all = T.grad(error, w_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "('An update must have the same type as the original shared variable (shared_var=<TensorType(float32, matrix)>, shared_var.type=TensorType(float32, matrix), update_val=Elemwise{sub,no_inplace}.0, update_val.type=TensorType(float64, matrix)).', 'If the difference is related to the broadcast pattern, you can call the tensor.unbroadcast(var, axis_to_unbroadcast[, ...]) function to remove broadcastable dimensions.')",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\hjkim\\Anaconda3\\lib\\site-packages\\theano\\compile\\pfunc.py\u001b[0m in \u001b[0;36mrebuild_collect_shared\u001b[1;34m(outputs, inputs, replace, updates, rebuild_strict, copy_inputs_over, no_default_updates)\u001b[0m\n\u001b[0;32m    192\u001b[0m             update_val = store_into.type.filter_variable(update_val,\n\u001b[1;32m--> 193\u001b[1;33m                                                          allow_convert=False)\n\u001b[0m\u001b[0;32m    194\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\hjkim\\Anaconda3\\lib\\site-packages\\theano\\tensor\\type.py\u001b[0m in \u001b[0;36mfilter_variable\u001b[1;34m(self, other, allow_convert)\u001b[0m\n\u001b[0;32m    234\u001b[0m                  \u001b[0mother\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 235\u001b[1;33m                  self=self))\n\u001b[0m\u001b[0;32m    236\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Cannot convert Type TensorType(float64, matrix) (of Variable Elemwise{sub,no_inplace}.0) into Type TensorType(float32, matrix). You can try to manually convert Elemwise{sub,no_inplace}.0 into a TensorType(float32, matrix).",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-311-09a8a4c424de>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mupd\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mupd_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw_all\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mg_all\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mfn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtheano\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merror\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mupdates\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mupd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_input_downcast\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Users\\hjkim\\Anaconda3\\lib\\site-packages\\theano\\compile\\function.py\u001b[0m in \u001b[0;36mfunction\u001b[1;34m(inputs, outputs, mode, updates, givens, no_default_updates, accept_inplace, name, rebuild_strict, allow_input_downcast, profile, on_unused_input)\u001b[0m\n\u001b[0;32m    324\u001b[0m                    \u001b[0mon_unused_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mon_unused_input\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    325\u001b[0m                    \u001b[0mprofile\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mprofile\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 326\u001b[1;33m                    output_keys=output_keys)\n\u001b[0m\u001b[0;32m    327\u001b[0m     \u001b[1;31m# We need to add the flag check_aliased inputs if we have any mutable or\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    328\u001b[0m     \u001b[1;31m# borrowed used defined inputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\hjkim\\Anaconda3\\lib\\site-packages\\theano\\compile\\pfunc.py\u001b[0m in \u001b[0;36mpfunc\u001b[1;34m(params, outputs, mode, updates, givens, no_default_updates, accept_inplace, name, rebuild_strict, allow_input_downcast, profile, on_unused_input, output_keys)\u001b[0m\n\u001b[0;32m    447\u001b[0m                                          \u001b[0mrebuild_strict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrebuild_strict\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    448\u001b[0m                                          \u001b[0mcopy_inputs_over\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 449\u001b[1;33m                                          no_default_updates=no_default_updates)\n\u001b[0m\u001b[0;32m    450\u001b[0m     \u001b[1;31m# extracting the arguments\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    451\u001b[0m     \u001b[0minput_variables\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcloned_extended_outputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother_stuff\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moutput_vars\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\hjkim\\Anaconda3\\lib\\site-packages\\theano\\compile\\pfunc.py\u001b[0m in \u001b[0;36mrebuild_collect_shared\u001b[1;34m(outputs, inputs, replace, updates, rebuild_strict, copy_inputs_over, no_default_updates)\u001b[0m\n\u001b[0;32m    206\u001b[0m                        ' function to remove broadcastable dimensions.')\n\u001b[0;32m    207\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 208\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merr_msg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merr_sug\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    209\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mupdate_val\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mstore_into\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: ('An update must have the same type as the original shared variable (shared_var=<TensorType(float32, matrix)>, shared_var.type=TensorType(float32, matrix), update_val=Elemwise{sub,no_inplace}.0, update_val.type=TensorType(float64, matrix)).', 'If the difference is related to the broadcast pattern, you can call the tensor.unbroadcast(var, axis_to_unbroadcast[, ...]) function to remove broadcastable dimensions.')"
     ]
    }
   ],
   "source": [
    "upd = upd_dict(w_all, g_all, lr)\n",
    "fn = theano.function(all_args, error, updates = upd, allow_input_downcast = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combined weights\n",
    "\n",
    "We can make the previous section simpler and gaster by concatenating the hidden and input matrices and inuts together. We're not going to step through this cell by cell - you'll see it's identical to the previous section except for this concatenation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = (shared(np.concatenate([np.eye(n_hidden), normal(size = (n_input, n_hidden))]).astype(np.float32)),  init_bias(n_hidden))\n",
    "\n",
    "rW = wgts_and_bias(n_input + n_hidden, n_hidden)\n",
    "uW = wgts_and_bias(n_input + n_hidden, n_hidden)\n",
    "W_y = wgts_and_bias(n_hidden, n_output)\n",
    "w_all = list(chain.from_iterable([W, W_y, uW, rW]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gate(m, W, b): return nnet.sigmoid(T.dot(m,W) + b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step(x, h, W, b, W_y, b_y, uW, ub, rW, rb):\n",
    "    m = T.concatenate([h, x])\n",
    "    reset = gate(m, rW, rb)\n",
    "    update = gate(m, uW, ub)\n",
    "    m = T.concatenate([h * reset, x])\n",
    "    h_new = gate(m, W, b)\n",
    "    h = update * h + (1.0 - update) * h_new\n",
    "    y = nnet.softmax(T.dot(h, W_y) + b_y)\n",
    "    return h, T.flatten(y, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "[v_h, v_y], _ = theano.scan(step, sequences = t_inp, outputs_info = [t_h0, None], non_sequences = w_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def upd_dict(wgts, grads, lr):\n",
    "    return OrderedDict({w: w-g*lr for (w,g) in zip(wgts, grads)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "error = nnet.categorical_crossentropy(v_y, t_outp).sum()\n",
    "g_all = T.grad(error, w_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "('An update must have the same type as the original shared variable (shared_var=<TensorType(float32, matrix)>, shared_var.type=TensorType(float32, matrix), update_val=Elemwise{sub,no_inplace}.0, update_val.type=TensorType(float64, matrix)).', 'If the difference is related to the broadcast pattern, you can call the tensor.unbroadcast(var, axis_to_unbroadcast[, ...]) function to remove broadcastable dimensions.')",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\hjkim\\Anaconda3\\lib\\site-packages\\theano\\compile\\pfunc.py\u001b[0m in \u001b[0;36mrebuild_collect_shared\u001b[1;34m(outputs, inputs, replace, updates, rebuild_strict, copy_inputs_over, no_default_updates)\u001b[0m\n\u001b[0;32m    192\u001b[0m             update_val = store_into.type.filter_variable(update_val,\n\u001b[1;32m--> 193\u001b[1;33m                                                          allow_convert=False)\n\u001b[0m\u001b[0;32m    194\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\hjkim\\Anaconda3\\lib\\site-packages\\theano\\tensor\\type.py\u001b[0m in \u001b[0;36mfilter_variable\u001b[1;34m(self, other, allow_convert)\u001b[0m\n\u001b[0;32m    234\u001b[0m                  \u001b[0mother\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 235\u001b[1;33m                  self=self))\n\u001b[0m\u001b[0;32m    236\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Cannot convert Type TensorType(float64, matrix) (of Variable Elemwise{sub,no_inplace}.0) into Type TensorType(float32, matrix). You can try to manually convert Elemwise{sub,no_inplace}.0 into a TensorType(float32, matrix).",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-331-09a8a4c424de>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mupd\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mupd_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw_all\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mg_all\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mfn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtheano\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merror\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mupdates\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mupd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_input_downcast\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Users\\hjkim\\Anaconda3\\lib\\site-packages\\theano\\compile\\function.py\u001b[0m in \u001b[0;36mfunction\u001b[1;34m(inputs, outputs, mode, updates, givens, no_default_updates, accept_inplace, name, rebuild_strict, allow_input_downcast, profile, on_unused_input)\u001b[0m\n\u001b[0;32m    324\u001b[0m                    \u001b[0mon_unused_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mon_unused_input\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    325\u001b[0m                    \u001b[0mprofile\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mprofile\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 326\u001b[1;33m                    output_keys=output_keys)\n\u001b[0m\u001b[0;32m    327\u001b[0m     \u001b[1;31m# We need to add the flag check_aliased inputs if we have any mutable or\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    328\u001b[0m     \u001b[1;31m# borrowed used defined inputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\hjkim\\Anaconda3\\lib\\site-packages\\theano\\compile\\pfunc.py\u001b[0m in \u001b[0;36mpfunc\u001b[1;34m(params, outputs, mode, updates, givens, no_default_updates, accept_inplace, name, rebuild_strict, allow_input_downcast, profile, on_unused_input, output_keys)\u001b[0m\n\u001b[0;32m    447\u001b[0m                                          \u001b[0mrebuild_strict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrebuild_strict\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    448\u001b[0m                                          \u001b[0mcopy_inputs_over\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 449\u001b[1;33m                                          no_default_updates=no_default_updates)\n\u001b[0m\u001b[0;32m    450\u001b[0m     \u001b[1;31m# extracting the arguments\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    451\u001b[0m     \u001b[0minput_variables\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcloned_extended_outputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother_stuff\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moutput_vars\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\hjkim\\Anaconda3\\lib\\site-packages\\theano\\compile\\pfunc.py\u001b[0m in \u001b[0;36mrebuild_collect_shared\u001b[1;34m(outputs, inputs, replace, updates, rebuild_strict, copy_inputs_over, no_default_updates)\u001b[0m\n\u001b[0;32m    206\u001b[0m                        ' function to remove broadcastable dimensions.')\n\u001b[0;32m    207\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 208\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merr_msg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merr_sug\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    209\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mupdate_val\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mstore_into\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: ('An update must have the same type as the original shared variable (shared_var=<TensorType(float32, matrix)>, shared_var.type=TensorType(float32, matrix), update_val=Elemwise{sub,no_inplace}.0, update_val.type=TensorType(float64, matrix)).', 'If the difference is related to the broadcast pattern, you can call the tensor.unbroadcast(var, axis_to_unbroadcast[, ...]) function to remove broadcastable dimensions.')"
     ]
    }
   ],
   "source": [
    "upd = upd_dict(w_all, g_all, lr)\n",
    "fn = theano.function(all_args, error, updates = upd, allow_input_downcast = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-332-7891c00b1793>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0merr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0ml_rate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.01\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0merr\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_hidden\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ml_rate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m1000\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m999\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "err = 0.\n",
    "l_rate = 0.01\n",
    "for i in range(len(X)):\n",
    "    err += fn(zp.zeros(n_hidden), X[i], Y[i], l_rate)\n",
    "    if i % 1000 == 999:\n",
    "        print('Error:{.2f}'.fomat(err / 1000))\n",
    "        err = 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
