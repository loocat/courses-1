{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lesson 6\n",
    "\n",
    "[lesson 6 wiki](http://wiki.fast.ai/index.php/Lesson_6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import utils\n",
    "import imp\n",
    "imp.reload(utils)\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "We're going to download the collected works of Nietzsche to use a sout data for this class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corpus length: 600893\n"
     ]
    }
   ],
   "source": [
    "path = get_file('nietzsche.txt', origin='http://s3.amazonaws.com/text-datasets/nietzsche.txt')\n",
    "text = open(path).read()\n",
    "print('corpus length:', len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total chars 85\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars) + 1\n",
    "print('total chars', vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes it's useful to have zero value in the dataset, e.g. for padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "chars.insert(0, '\\0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n !\"\\'(),-.0123456789:;=?ABCDEFGHIJKLMNOPQRSTUVWXYZ[]_abcdefghijklmnopqrstuvwxy'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''.join(chars[1:-6])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Map from chars to indices and back again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*idx* will be the data we use from now own - it simply converts all the characters to their index (based on the mapping above)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "idx = [char_indices[c] for c in text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[40, 42, 29, 30, 25, 27, 29, 1, 1, 1]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'PREFACE\\n\\n\\nSUPPOSING that Truth is a woman--what then? Is there not gro'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''.join(indices_char[i] for i in idx[:70])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 char model\n",
    "\n",
    "### create inputs\n",
    "\n",
    "Create a list of every 4th character, starting at the 0th, 1st, 2nd, then 3rd characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cs = 3\n",
    "c1_dat = [idx[i] for i in range(0, len(idx) - 1 - cs, cs)]\n",
    "c2_dat = [idx[i+1] for i in range(0, len(idx) - 1 - cs, cs)]\n",
    "c3_dat = [idx[i+2] for i in range(0, len(idx) - 1 - cs, cs)]\n",
    "c4_dat = [idx[i+3] for i in range(0, len(idx) - 1 - cs, cs)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x1 = np.stack(c1_dat[:-2])\n",
    "x2 = np.stack(c2_dat[:-2])\n",
    "x3 = np.stack(c3_dat[:-2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = np.stack(c4_dat[:-2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first 4 inputs and outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([40, 30, 29,  1]), array([42, 25,  1, 43]), array([29, 27,  1, 45]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1[:4], x2[:4], x3[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([30, 29,  1, 40])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((200295,), (200295,))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of latent factors to create (i.e. the size of the embedding matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_fac = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create inpus and embedding outputs for each our 3 character inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def embedding_input(name, n_in, n_out):\n",
    "    inp = Input(shape = (1,), dtype = 'int64', name = name)\n",
    "    emb = Embedding(n_in, n_out, input_length = 1)(inp)\n",
    "    return inp, Flatten()(emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "c1_in, c1 = embedding_input('c1', vocab_size, n_fac)\n",
    "c2_in, c2 = embedding_input('c2', vocab_size, n_fac)\n",
    "c3_in, c3 = embedding_input('c3', vocab_size, n_fac)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create and train model\n",
    "\n",
    "Pick a size for out hidden state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_hidden = 256"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the 'green arrow' from our diagram - the layer operation from input to hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dense_in = Dense(n_hidden, activation = 'relu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our first hidden activation is simply this function applied to the result of the embedding of the first character."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c1_hidden = dense_in(c1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the 'orange arrow' from our diagram - the layer operation from hidden to hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dense_hidden = Dense(n_hidden, activation = 'tanh')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our second and third hidden activations sum up the previous hidden state (agter applying dense_hidden) to the new input state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hjkim\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\hjkim\\Anaconda3\\lib\\site-packages\\keras-2.0.8-py3.6.egg\\keras\\legacy\\layers.py:458: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n"
     ]
    }
   ],
   "source": [
    "c2_dense = dense_in(c2)\n",
    "hidden_2 = dense_hidden(c1_hidden)\n",
    "c2_hidden = merge([c2_dense, hidden_2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hjkim\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\hjkim\\Anaconda3\\lib\\site-packages\\keras-2.0.8-py3.6.egg\\keras\\legacy\\layers.py:458: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n"
     ]
    }
   ],
   "source": [
    "c3_dense = dense_in(c3)\n",
    "hidden_3 = dense_hidden(c2_hidden)\n",
    "c3_hidden = merge([c3_dense, hidden_3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the 'blue arrow' from out diagram - the layer operation from hidden to output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dense_out = Dense(vocab_size, activation = 'softmax')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The third hidden state is the inupt to our output layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c4_out = dense_out(c3_hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Model([c1_in, c2_in, c3_in], c4_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = 'sparse_categorical_crossentropy', optimizer = Adam())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.optimizer.lr = 1e-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "200295/200295 [==============================] - 37s - loss: 4.4135    \n",
      "Epoch 2/4\n",
      "200295/200295 [==============================] - 36s - loss: 4.2959    \n",
      "Epoch 3/4\n",
      "200295/200295 [==============================] - 36s - loss: 4.0376    \n",
      "Epoch 4/4\n",
      "200295/200295 [==============================] - 36s - loss: 3.6372    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0xde8ae80>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit([x1, x2, x3], y, batch_size = 64, epochs = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.optimizer.kr = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "200295/200295 [==============================] - 36s - loss: 3.3093    \n",
      "Epoch 2/4\n",
      "200295/200295 [==============================] - 36s - loss: 3.1867    \n",
      "Epoch 3/4\n",
      "200295/200295 [==============================] - 36s - loss: 3.1448    \n",
      "Epoch 4/4\n",
      "200295/200295 [==============================] - 36s - loss: 3.1227    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0xbb1e358>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit([x1, x2, x3], y, batch_size = 64, epochs = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.optimizer.lr = 1e-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "200295/200295 [==============================] - 35s - loss: 3.1073    \n",
      "Epoch 2/4\n",
      "200295/200295 [==============================] - 35s - loss: 3.0955    \n",
      "Epoch 3/4\n",
      "200295/200295 [==============================] - 35s - loss: 3.0859    \n",
      "Epoch 4/4\n",
      "200295/200295 [==============================] - 35s - loss: 3.0776    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x13ed9780>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit([x1, x2, x3], y, batch_size = 64, epochs = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.optimizer.lr = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "200295/200295 [==============================] - 36s - loss: 3.0699    \n",
      "Epoch 2/4\n",
      "200295/200295 [==============================] - 36s - loss: 3.0626    \n",
      "Epoch 3/4\n",
      "200295/200295 [==============================] - 36s - loss: 3.0553    \n",
      "Epoch 4/4\n",
      "200295/200295 [==============================] - 36s - loss: 3.0479    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x13ed90b8>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit([x1, x2, x3], y, batch_size = 64, epochs = 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_next(inp):\n",
    "    idxs = [char_indices[c] for c in inp]\n",
    "    arrs = [np.array(i)[np.newaxis] for i in idxs]\n",
    "    p = model.predict(arrs)\n",
    "    i = np.argmax(p)\n",
    "    return chars[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' '"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_next('phi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' '"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_next(' th')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' '"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_next(' an')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Out first RNN!\n",
    "\n",
    "### Create inputs\n",
    "\n",
    "This is the size of out unrolled RNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cs = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each of 0 through 7, create a list of every 8th character with taht starting point. These will be the 8 inputs to out model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c_in_dat = [[idx[i+n] for i in range(0, len(idx)-1-cs, cs)] for n in range(cs)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then create a list of the next character in each of these series. This will be the labels for our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c_out_dat = [idx[i+cs] for i in range(0, len(idx)-1-cs, cs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = [np.stack(c[:-2]) for c in c_in_dat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, (75109,))"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(xs), xs[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.stack(c_out_dat[:-2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So each column below is one series of 8 characters from the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([40,  1, 33,  2, 72, 67, 73,  2]),\n",
       " array([42,  1, 38, 44,  2,  9, 61, 73]),\n",
       " array([29, 43, 31, 71, 54,  9, 58, 61]),\n",
       " array([30, 45,  2, 74,  2, 76, 67, 58]),\n",
       " array([25, 40, 73, 73, 76, 61, 24, 71]),\n",
       " array([27, 40, 61, 61, 68, 54,  2, 58]),\n",
       " array([29, 39, 54,  2, 66, 73, 33,  2]),\n",
       " array([ 1, 43, 73, 62, 54,  2, 72, 67])]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[xs[n][:cs] for n in range(cs)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "..and this is the next character after each sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1, 33,  2, 72, 67, 73,  2, 68])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[:cs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_fac = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create and train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def embedding_input(name, n_in, n_out) :\n",
    "    inp = Input(shape = (1,), dtype = 'int64', name = name + '_in')\n",
    "    emb = Embedding(n_in, n_out, input_length = 1, name = name + '_emb')(inp)\n",
    "    return inp, Flatten()(emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c_ins = [embedding_input('c' + str(n), vocab_size, n_fac) for n in range(cs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_hidden = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_in = Dense(n_hidden, activation = 'relu')\n",
    "dense_hidden = Dense(n_hidden, activation = 'relu', kernel_initializer = 'identity')\n",
    "dense_out = Dense(vocab_size, activation = 'softmax')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first character of each sequence goes through dense_in(), to create out first hidden activations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hidden = dense_in(c_ins[0][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then for each successive layer we combine the output of dense_in() on the next character with the output of dense_hidden() on the current hidden state, to create new hidden state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hjkim\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\Users\\hjkim\\Anaconda3\\lib\\site-packages\\keras-2.0.8-py3.6.egg\\keras\\legacy\\layers.py:458: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, cs):\n",
    "    c_dense = dense_in(c_ins[i][1])\n",
    "    hidden = dense_hidden(hidden)\n",
    "    hidden = merge([c_dense, hidden])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Putting the final hidden state through desnse_out() gives us our output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c_out = dense_out(hidden)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now we can create out model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model([c[0] for c in c_ins], c_out)\n",
    "model.compile(loss = 'sparse_categorical_crossentropy', optimizer = Adam())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n",
      "75109/75109 [==============================] - 27s - loss: 2.5394    \n",
      "Epoch 2/12\n",
      "75109/75109 [==============================] - 25s - loss: 2.2536    \n",
      "Epoch 3/12\n",
      "75109/75109 [==============================] - 25s - loss: 2.1452    \n",
      "Epoch 4/12\n",
      "75109/75109 [==============================] - 25s - loss: 2.0735    \n",
      "Epoch 5/12\n",
      "75109/75109 [==============================] - 25s - loss: 2.0166    \n",
      "Epoch 6/12\n",
      "75109/75109 [==============================] - 25s - loss: 1.9706    \n",
      "Epoch 7/12\n",
      "75109/75109 [==============================] - 25s - loss: 1.9304    \n",
      "Epoch 8/12\n",
      "75109/75109 [==============================] - 25s - loss: 1.8952    \n",
      "Epoch 9/12\n",
      "75109/75109 [==============================] - 25s - loss: 1.8650    \n",
      "Epoch 10/12\n",
      "75109/75109 [==============================] - 25s - loss: 1.8374    \n",
      "Epoch 11/12\n",
      "75109/75109 [==============================] - 25s - loss: 1.8123    \n",
      "Epoch 12/12\n",
      "75109/75109 [==============================] - 25s - loss: 1.7874    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x11e987b8>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(xs, y, batch_size = 64, epochs = 12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_next(inp):\n",
    "    idxs = [np.array(char_indices[c])[np.newaxis] for c in inp]\n",
    "    p = model.predict(idxs)\n",
    "    return chars[np.argmax(p)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'e'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_next('for thos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'t'"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_next('part of ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'n'"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_next('queens a')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Our first RNN with keras!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_hidden, n_fac, cs, vocab_size = (256, 42, 8, 86)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is nearly exactly equivalent to the RNN we built ourselves in the previous section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hjkim\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `SimpleRNN` call to the Keras 2 API: `SimpleRNN(256, activation=\"relu\", recurrent_initializer=\"identity\")`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Embedding(vocab_size, n_fac, input_length = cs),\n",
    "    SimpleRNN(n_hidden, activation = 'relu', inner_init = 'identity'),\n",
    "    Dense(vocab_size, activation = 'softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_5 (Embedding)      (None, 8, 42)             3612      \n",
      "_________________________________________________________________\n",
      "simple_rnn_2 (SimpleRNN)     (None, 256)               76544     \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 86)                22102     \n",
      "=================================================================\n",
      "Total params: 102,258\n",
      "Trainable params: 102,258\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss = 'sparse_categorical_crossentropy', optimizer = Adam())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "75109/75109 [==============================] - 28s - loss: 2.8256    - ETA: 0s - loss: 2.82\n",
      "Epoch 2/8\n",
      "75109/75109 [==============================] - 27s - loss: 2.2965    \n",
      "Epoch 3/8\n",
      "75109/75109 [==============================] - 27s - loss: 2.0832    \n",
      "Epoch 4/8\n",
      "75109/75109 [==============================] - 27s - loss: 1.9419    \n",
      "Epoch 5/8\n",
      "75109/75109 [==============================] - 27s - loss: 1.8365    \n",
      "Epoch 6/8\n",
      "75109/75109 [==============================] - 27s - loss: 1.7537    \n",
      "Epoch 7/8\n",
      "75109/75109 [==============================] - 27s - loss: 1.6857    \n",
      "Epoch 8/8\n",
      "75109/75109 [==============================] - 27s - loss: 1.6285    - ETA\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x11decf98>"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(np.concatenate(xs, axis = 1), y, batch_size = 64, epochs = 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_next_keras(inp):\n",
    "    idxs = [char_indices[c] for c in inp]\n",
    "    arrs = np.array(idxs)[np.newaxis,:]\n",
    "    p = model.predict(arrs)[0]\n",
    "    return chars[np.argmax(p)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'t'"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_next_keras('this is ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'t'"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_next_keras('part of ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'n'"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_next_keras('queens a')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Returning sequeces\n",
    "\n",
    "### Create inputs\n",
    "\n",
    "To use a sequence model, we can leave out input unchanged - but we have to change out output to a sequence (of course!)\n",
    "\n",
    "Here, c_out_dat is identical to c_in_dat, but moved across 1 character,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c_out_dat = [[idx[i+n] for i in range(1, len(idx)-cs, cs)] for n in range(cs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "ys = [np.stack(c[:-2]) for c in c_out_dat]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading down each column shows one set of inputs and outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[40],\n",
       "        [ 1],\n",
       "        [33],\n",
       "        [ 2],\n",
       "        [72],\n",
       "        [67],\n",
       "        [73],\n",
       "        [ 2]]), array([[42],\n",
       "        [ 1],\n",
       "        [38],\n",
       "        [44],\n",
       "        [ 2],\n",
       "        [ 9],\n",
       "        [61],\n",
       "        [73]]), array([[29],\n",
       "        [43],\n",
       "        [31],\n",
       "        [71],\n",
       "        [54],\n",
       "        [ 9],\n",
       "        [58],\n",
       "        [61]]), array([[30],\n",
       "        [45],\n",
       "        [ 2],\n",
       "        [74],\n",
       "        [ 2],\n",
       "        [76],\n",
       "        [67],\n",
       "        [58]]), array([[25],\n",
       "        [40],\n",
       "        [73],\n",
       "        [73],\n",
       "        [76],\n",
       "        [61],\n",
       "        [24],\n",
       "        [71]]), array([[27],\n",
       "        [40],\n",
       "        [61],\n",
       "        [61],\n",
       "        [68],\n",
       "        [54],\n",
       "        [ 2],\n",
       "        [58]]), array([[29],\n",
       "        [39],\n",
       "        [54],\n",
       "        [ 2],\n",
       "        [66],\n",
       "        [73],\n",
       "        [33],\n",
       "        [ 2]]), array([[ 1],\n",
       "        [43],\n",
       "        [73],\n",
       "        [62],\n",
       "        [54],\n",
       "        [ 2],\n",
       "        [72],\n",
       "        [67]])]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[xs[n][:cs] for n in range(cs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([42,  1, 38, 44,  2,  9, 61, 73]),\n",
       " array([29, 43, 31, 71, 54,  9, 58, 61]),\n",
       " array([30, 45,  2, 74,  2, 76, 67, 58]),\n",
       " array([25, 40, 73, 73, 76, 61, 24, 71]),\n",
       " array([27, 40, 61, 61, 68, 54,  2, 58]),\n",
       " array([29, 39, 54,  2, 66, 73, 33,  2]),\n",
       " array([ 1, 43, 73, 62, 54,  2, 72, 67]),\n",
       " array([ 1, 33,  2, 72, 67, 73,  2, 68])]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[ys[n][:cs] for n in range(cs)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create and train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hjkim\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(256, activation=\"relu\", kernel_initializer=\"identity\")`\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "dense_in = Dense(n_hidden, activation = 'relu')\n",
    "dense_hidden = Dense(n_hidden, activation = 'relu', init = 'identity')\n",
    "dense_out = Dense(vocab_size, activation = 'softmax', name = 'output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp1 = Input(shape = (n_fac,), name = 'zero')\n",
    "hidden = dense_in(inp1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hjkim\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  \n",
      "C:\\Users\\hjkim\\Anaconda3\\lib\\site-packages\\keras-2.0.8-py3.6.egg\\keras\\legacy\\layers.py:458: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n"
     ]
    }
   ],
   "source": [
    "outs = []\n",
    "\n",
    "for i in range(cs):\n",
    "    c_dense = dense_in(c_ins[i][1])\n",
    "    hidden = dense_hidden(hidden)\n",
    "    hidden = merge([c_dense, hidden], mode = 'sum')\n",
    "    \n",
    "    # every Layer new has an output\n",
    "    outs.append(dense_out(hidden))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Model([inp1] + [c[0] for c in c_ins], outs)\n",
    "model.compile(loss = 'sparse_categorical_crossentropy', optimizer = Adam())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(75109, 42)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zeros = np.tile(np.zeros(n_fac), (len(xs[0]), 1))\n",
    "zeros.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n",
      "75109/75109 [==============================] - 51s - loss: 20.1358 - output_loss_1: 2.7132 - output_loss_2: 2.5710 - output_loss_3: 2.5126 - output_loss_4: 2.4820 - output_loss_5: 2.4681 - output_loss_6: 2.4675 - output_loss_7: 2.4702 - output_loss_8: 2.4512     - ETA: 23s - loss: 21.4945 - output_loss_1: 2.8690 - output_loss_2: 2.7222 - output_loss_3:  - ETA: 13s - loss: 20.8039 - outpu\n",
      "Epoch 2/12\n",
      "75109/75109 [==============================] - 37s - loss: 17.8707 - output_loss_1: 2.5138 - output_loss_2: 2.3561 - output_loss_3: 2.2294 - output_loss_4: 2.1778 - output_loss_5: 2.1545 - output_loss_6: 2.1492 - output_loss_7: 2.1581 - output_loss_8: 2.1317    \n",
      "Epoch 3/12\n",
      "75109/75109 [==============================] - 37s - loss: 17.2690 - output_loss_1: 2.4985 - output_loss_2: 2.3340 - output_loss_3: 2.1675 - output_loss_4: 2.0904 - output_loss_5: 2.0532 - output_loss_6: 2.0474 - output_loss_7: 2.0516 - output_loss_8: 2.0264     - ETA: 33s - loss: 17.3656 - output_ - ETA: 20s - loss: 17.3597 - output_loss_1: 2.4981 - output_loss_2: 2.3296 - output_loss_3: 2.1695 - output_loss_4: 2.1016 - output_loss_5: 2.0654 - output_loss_6: 2.0762 - output_loss_7: 2.0658 - ou - ETA: 19s - loss: 17.3511 - output_loss_1: 2.4963 - output_ - ETA: 9s - loss: 17.3040 - output_loss_1: 2.4974 - output_loss_2: 2.3351 - output_loss_3: 2.1669 - output_loss_4: 2.0947 - output_lo\n",
      "Epoch 4/12\n",
      "75109/75109 [==============================] - 37s - loss: 16.8996 - output_loss_1: 2.4912 - output_loss_2: 2.3247 - output_loss_3: 2.1372 - output_loss_4: 2.0385 - output_loss_5: 1.9893 - output_loss_6: 1.9773 - output_loss_7: 1.9838 - output_loss_8: 1.9576     - ETA: 33s - loss: 16.9901 - output_loss_1: 2 - ETA: 2s - loss: 16.9102 - output_loss_1: 2.4913 - output_loss_2: 2.3237 - output_loss_3: 2.1388 - output_loss_4: 2.0428 - output_loss_5: 1.9916 -\n",
      "Epoch 5/12\n",
      "75109/75109 [==============================] - 38s - loss: 16.6463 - output_loss_1: 2.4870 - output_loss_2: 2.3187 - output_loss_3: 2.1201 - output_loss_4: 2.0046 - output_loss_5: 1.9458 - output_loss_6: 1.9278 - output_loss_7: 1.9339 - output_loss_8: 1.9083    \n",
      "Epoch 6/12\n",
      "75109/75109 [==============================] - 37s - loss: 16.4602 - output_loss_1: 2.4849 - output_loss_2: 2.3145 - output_loss_3: 2.1069 - output_loss_4: 1.9810 - output_loss_5: 1.9136 - output_loss_6: 1.8921 - output_loss_7: 1.8958 - output_loss_8: 1.8714     ETA: 7s - loss: 16.4712 - output_loss_1: 2.4829 - output_loss_2: 2.3184 - output_ - ETA: 3s - loss: 16.4654 - output_loss_1: 2.4853 - output_loss_2: 2.3170 - output_loss_3: 2.1070 - output_loss_4: \n",
      "Epoch 7/12\n",
      "75109/75109 [==============================] - 37s - loss: 16.3158 - output_loss_1: 2.4837 - output_loss_2: 2.3114 - output_loss_3: 2.0977 - output_loss_4: 1.9629 - output_loss_5: 1.8892 - output_loss_6: 1.8629 - output_loss_7: 1.8660 - output_loss_8: 1.8421     - ETA: 36s - loss: 16.3513 - output_loss_1: 2.4601 - output_loss_2: 2.3047 - output_loss_3: 2.0735 - ou - ETA: 28s - loss: 16.2832 - output_loss_1: 2.4825 -\n",
      "Epoch 8/12\n",
      "75109/75109 [==============================] - 37s - loss: 16.2009 - output_loss_1: 2.4820 - output_loss_2: 2.3100 - output_loss_3: 2.0907 - output_loss_4: 1.9469 - output_loss_5: 1.8698 - output_loss_6: 1.8405 - output_loss_7: 1.8436 - output_loss_8: 1.8175    \n",
      "Epoch 9/12\n",
      "75109/75109 [==============================] - 37s - loss: 16.1015 - output_loss_1: 2.4808 - output_loss_2: 2.3081 - output_loss_3: 2.0854 - output_loss_4: 1.9380 - output_loss_5: 1.8522 - output_loss_6: 1.8198 - output_loss_7: 1.8203 - output_loss_8: 1.7969     - ETA: 30s - loss: 16.0814 - output_loss_1: 2.4 - ETA: 20s - loss: 16.0878 - output_loss_1: 2.4874 - output_loss_2: 2.3083 - ou - ETA: 11s - loss: 16.0975 - output_loss_1: 2.4809 - output_loss_2: 2.3064 - output_loss_3: 2.0858 - outp\n",
      "Epoch 10/12\n",
      "75109/75109 [==============================] - 37s - loss: 16.0282 - output_loss_1: 2.4797 - output_loss_2: 2.3069 - output_loss_3: 2.0804 - output_loss_4: 1.9254 - output_loss_5: 1.8407 - output_loss_6: 1.8074 - output_loss_7: 1.8058 - output_loss_8: 1.7820     ETA: 3s - loss: 16.0202 - output_loss_1: 2.4763 - output_loss_2: 2.3076 - output_loss_3: 2.0807 - output_loss_4: 1.9247 - output_loss_5: 1.8389 - output_loss_6: 1.8065 - output_loss_7: 1.8054 - output_ - ETA: 3s - loss: 16.0190 - output_loss_1: 2.4769 - output_loss_2: 2.3079 - output_loss_3: 2.0806 - output_loss_4\n",
      "Epoch 11/12\n",
      "75109/75109 [==============================] - 38s - loss: 15.9605 - output_loss_1: 2.4792 - output_loss_2: 2.3056 - output_loss_3: 2.0770 - output_loss_4: 1.9186 - output_loss_5: 1.8293 - output_loss_6: 1.7914 - output_loss_7: 1.7933 - output_loss_8: 1.7660    \n",
      "Epoch 12/12\n",
      "75109/75109 [==============================] - 37s - loss: 15.9032 - output_loss_1: 2.4787 - output_loss_2: 2.3034 - output_loss_3: 2.0742 - output_loss_4: 1.9116 - output_loss_5: 1.8203 - output_loss_6: 1.7816 - output_loss_7: 1.7799 - output_loss_8: 1.7534    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x10466780>"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit([zeros] + xs, ys, batch_size = 64, epochs = 12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_nexts(inp):\n",
    "    idxs = [char_indices[c] for c in inp]\n",
    "    arrs = [np.array(i)[np.newaxis] for i in idxs]\n",
    "    p = model.predict([np.zeros(n_fac)[np.newaxis,:]] + arrs)\n",
    "    print(list(inp))\n",
    "    return [chars[np.argmax(o)] for o in p]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' ', 't', 'h', 'i', 's', ' ', 'i', 's']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['t', 'h', 'e', 't', ' ', 'e', 'n', ' ']"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_nexts(' this is')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' ', 'p', 'a', 'r', 't', ' ', 'o', 'f']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['t', 'o', 'r', 't', ' ', 'o', 'f', ' ']"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_nexts(' part of')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequence model with keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(256, 42, 8, 86)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_hidden, n_fac, cs, vocab_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To convert out previous keras model into a sequence model, simply add the 'return_sequences = True' parameter, and add TimeDistributed() around out dense layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hjkim\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `SimpleRNN` call to the Keras 2 API: `SimpleRNN(256, return_sequences=True, activation=\"relu\", recurrent_initializer=\"identity\")`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Embedding(vocab_size, n_fac, input_length = cs),\n",
    "    SimpleRNN(n_hidden, return_sequences = True, activation = 'relu', inner_init = 'identity'),\n",
    "    TimeDistributed(Dense(vocab_size, activation = 'softmax'))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_8 (Embedding)      (None, 8, 42)             3612      \n",
      "_________________________________________________________________\n",
      "simple_rnn_4 (SimpleRNN)     (None, 8, 256)            76544     \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 8, 86)             22102     \n",
      "=================================================================\n",
      "Total params: 102,258\n",
      "Trainable params: 102,258\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss = 'sparse_categorical_crossentropy', optimizer = Adam())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(75109, 1)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_rnn = np.stack(np.squeeze(xs), axis = 1)\n",
    "y_rnn = np.atleast_3d(np.stack(ys, axis = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((75109, 8), (75109, 8, 1))"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_rnn.shape, y_rnn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "75109/75109 [==============================] - 42s - loss: 2.4372    \n",
      "Epoch 2/8\n",
      "75109/75109 [==============================] - 50s - loss: 1.9961    \n",
      "Epoch 3/8\n",
      "75109/75109 [==============================] - 41s - loss: 1.8822    \n",
      "Epoch 4/8\n",
      "75109/75109 [==============================] - 41s - loss: 1.8221    \n",
      "Epoch 5/8\n",
      "75109/75109 [==============================] - 41s - loss: 1.7848    \n",
      "Epoch 6/8\n",
      "75109/75109 [==============================] - 41s - loss: 1.7579    \n",
      "Epoch 7/8\n",
      "75109/75109 [==============================] - 42s - loss: 1.7382    \n",
      "Epoch 8/8\n",
      "75109/75109 [==============================] - 41s - loss: 1.7224    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c482f98>"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_rnn, y_rnn, batch_size = 64, epochs = 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_nexts_keras(inp):\n",
    "    idxs = [char_indices[c] for c in inp]\n",
    "    arrs = np.array(idxs)[np.newaxis, :]\n",
    "    p = model.predict(arrs)[0]\n",
    "    print(list(p))\n",
    "    return [chars[np.argmax(o)] for o in p]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([  1.3300e-08,   9.7863e-04,   9.3279e-03,   1.4379e-05,   9.3872e-03,   2.2838e-04,\n",
      "         4.0600e-03,   6.6583e-06,   8.0739e-05,   8.7644e-06,   1.8521e-05,   2.7755e-08,\n",
      "         2.4759e-04,   6.6310e-05,   5.1688e-05,   3.7037e-05,   3.7574e-05,   4.9740e-05,\n",
      "         2.9261e-05,   8.3142e-05,   1.4095e-05,   1.3405e-05,   1.1970e-05,   6.1021e-05,\n",
      "         2.2689e-05,   4.1309e-03,   2.2781e-03,   1.3450e-03,   1.5092e-03,   3.1624e-03,\n",
      "         3.7977e-03,   3.8464e-03,   1.7714e-03,   6.5103e-03,   2.2833e-04,   2.7988e-04,\n",
      "         1.5426e-03,   1.8487e-03,   1.9987e-03,   2.5050e-03,   2.5550e-03,   1.9709e-04,\n",
      "         1.4508e-03,   3.0313e-03,   5.9994e-03,   7.3280e-04,   4.2734e-04,   5.3910e-03,\n",
      "         2.3499e-06,   3.4971e-04,   3.5913e-05,   3.7655e-04,   2.0996e-07,   7.4795e-04,\n",
      "         1.4141e-01,   2.9348e-02,   2.6940e-02,   3.0382e-02,   2.2971e-02,   3.3395e-02,\n",
      "         1.2665e-02,   4.7787e-02,   6.8860e-02,   2.6954e-03,   3.7443e-03,   1.4519e-02,\n",
      "         3.7892e-02,   2.3908e-02,   8.7179e-02,   2.9475e-02,   2.0395e-03,   1.6407e-02,\n",
      "         6.1565e-02,   1.3998e-01,   1.1356e-02,   9.4995e-03,   6.0728e-02,   7.4810e-06,\n",
      "         2.3538e-03,   2.5185e-06,   2.4487e-08,   1.0245e-07,   1.4799e-08,   7.8997e-09,\n",
      "         2.9539e-07,   1.6838e-08], dtype=float32), array([  5.0954e-11,   1.2107e-06,   6.2233e-06,   5.8716e-07,   1.2774e-07,   5.4768e-05,\n",
      "         1.1797e-12,   3.2030e-08,   6.4584e-07,   6.7793e-08,   6.2295e-07,   7.7748e-11,\n",
      "         1.7456e-09,   6.1995e-11,   5.3411e-10,   9.1554e-10,   2.7912e-10,   1.4231e-09,\n",
      "         2.4810e-11,   1.7433e-11,   7.6551e-11,   8.2564e-07,   1.0783e-07,   8.5719e-12,\n",
      "         3.2506e-07,   8.2302e-06,   2.0202e-09,   3.2794e-09,   1.3251e-10,   4.3320e-05,\n",
      "         2.7442e-08,   7.9977e-10,   1.3287e-04,   2.1348e-05,   4.1755e-11,   1.5920e-07,\n",
      "         1.1989e-06,   6.0611e-08,   7.3020e-08,   1.3028e-04,   4.4937e-08,   4.9243e-12,\n",
      "         1.4454e-05,   3.7065e-08,   1.5101e-06,   5.9001e-06,   9.0475e-10,   2.6278e-08,\n",
      "         8.0281e-11,   5.7682e-06,   3.2279e-13,   1.3632e-10,   6.5659e-11,   6.0313e-08,\n",
      "         1.3075e-02,   1.6988e-08,   5.2345e-05,   8.7779e-10,   1.4297e-02,   3.3068e-07,\n",
      "         1.5790e-08,   6.5232e-01,   1.2141e-02,   5.5739e-09,   1.1431e-07,   2.8238e-04,\n",
      "         8.0956e-07,   8.3259e-06,   2.7461e-01,   5.1579e-07,   3.3835e-07,   2.6261e-02,\n",
      "         1.0383e-05,   5.0475e-05,   1.3170e-03,   1.3519e-07,   1.1158e-03,   7.9207e-10,\n",
      "         4.0165e-03,   5.8431e-06,   1.8164e-14,   1.6817e-11,   2.5875e-09,   1.0569e-12,\n",
      "         8.7417e-12,   8.4466e-11], dtype=float32), array([  4.3337e-10,   2.7518e-05,   2.1935e-04,   6.0540e-07,   5.8273e-06,   2.5710e-06,\n",
      "         7.9771e-11,   1.6759e-06,   1.7167e-05,   5.6194e-06,   7.5581e-06,   3.1319e-14,\n",
      "         1.2497e-11,   9.4757e-13,   1.1163e-11,   3.3156e-12,   1.6980e-13,   1.0148e-13,\n",
      "         1.0890e-13,   3.2678e-13,   2.1950e-14,   5.2512e-06,   8.5158e-07,   7.5290e-12,\n",
      "         1.6320e-06,   1.6661e-05,   2.5739e-09,   6.3700e-09,   9.3316e-08,   1.4103e-04,\n",
      "         1.5862e-09,   2.2419e-09,   4.0716e-09,   4.4345e-05,   1.3294e-08,   4.1941e-09,\n",
      "         8.5134e-08,   6.6007e-07,   4.0628e-08,   7.8988e-06,   2.1675e-07,   9.7444e-13,\n",
      "         3.8961e-07,   1.3115e-07,   4.4792e-06,   2.2669e-06,   1.2869e-09,   1.3838e-07,\n",
      "         6.2666e-10,   7.9491e-06,   8.9646e-11,   2.5693e-08,   8.6607e-10,   2.8721e-06,\n",
      "         1.4254e-01,   6.2372e-06,   7.9041e-08,   8.3775e-07,   6.8511e-01,   4.0530e-07,\n",
      "         2.3026e-07,   1.1883e-05,   1.0305e-01,   1.0132e-07,   1.3977e-07,   1.0185e-04,\n",
      "         1.8095e-04,   1.4961e-04,   4.2326e-02,   1.1172e-05,   1.2904e-07,   1.3856e-02,\n",
      "         1.2342e-04,   5.9127e-05,   9.7460e-03,   1.1298e-07,   8.5091e-07,   1.3465e-08,\n",
      "         2.2000e-03,   1.5476e-07,   1.3073e-07,   1.9178e-09,   3.1545e-09,   2.8465e-12,\n",
      "         3.1897e-10,   3.6199e-10], dtype=float32), array([  1.1021e-12,   9.7998e-07,   1.0083e-05,   3.4774e-07,   3.0656e-07,   6.3029e-08,\n",
      "         9.3825e-12,   2.8254e-07,   3.0533e-06,   6.9712e-06,   8.2143e-07,   3.7856e-14,\n",
      "         1.2819e-11,   9.1684e-12,   2.0530e-11,   5.1787e-13,   1.9408e-12,   7.4086e-14,\n",
      "         2.9343e-13,   1.6867e-13,   8.7865e-14,   1.7139e-07,   5.3006e-08,   6.9228e-19,\n",
      "         1.6568e-06,   5.6262e-09,   1.2877e-08,   4.0084e-06,   4.1620e-08,   3.7876e-07,\n",
      "         8.1564e-08,   3.6183e-07,   4.0024e-10,   6.8836e-08,   1.5016e-12,   7.0201e-10,\n",
      "         4.3252e-07,   4.6624e-07,   5.1513e-06,   2.1080e-08,   1.2741e-07,   2.3385e-13,\n",
      "         5.0210e-07,   1.0021e-04,   3.6170e-07,   4.0386e-09,   3.9056e-09,   2.2527e-08,\n",
      "         1.0360e-10,   1.6618e-11,   2.0616e-10,   5.6548e-09,   9.6155e-09,   5.0457e-06,\n",
      "         8.8132e-05,   3.0130e-05,   4.5478e-03,   2.5281e-04,   7.9151e-04,   1.7678e-04,\n",
      "         6.1743e-03,   3.0725e-04,   1.4543e-05,   3.8074e-07,   3.2150e-05,   1.9480e-04,\n",
      "         7.0111e-03,   4.3704e-01,   3.7775e-04,   5.3467e-05,   2.4830e-07,   2.8853e-03,\n",
      "         5.3533e-01,   1.8213e-03,   2.5545e-03,   6.9197e-05,   1.4943e-06,   5.7018e-05,\n",
      "         1.5156e-07,   4.8666e-05,   1.7956e-15,   1.3106e-13,   1.2499e-13,   1.4571e-12,\n",
      "         1.8062e-13,   9.1652e-14], dtype=float32), array([  1.8438e-12,   7.2921e-02,   9.0809e-01,   3.1339e-04,   2.1204e-04,   5.9832e-07,\n",
      "         1.1950e-12,   3.8993e-05,   9.1045e-03,   5.0184e-04,   1.8475e-03,   4.4922e-13,\n",
      "         6.1612e-13,   4.8277e-13,   1.6010e-11,   9.7119e-13,   2.1082e-12,   4.8015e-14,\n",
      "         3.8164e-13,   9.0244e-14,   2.5847e-13,   5.4948e-04,   7.5315e-04,   6.7775e-09,\n",
      "         5.6341e-04,   2.0664e-10,   4.3259e-09,   1.2603e-09,   8.4731e-11,   2.3345e-09,\n",
      "         1.4305e-11,   1.2616e-09,   7.1662e-09,   5.2802e-09,   3.2468e-11,   2.3012e-10,\n",
      "         2.4634e-10,   1.3824e-09,   2.8632e-10,   8.6135e-11,   8.7880e-09,   3.8523e-11,\n",
      "         6.7126e-11,   9.0432e-09,   3.5870e-07,   1.0812e-10,   1.1994e-11,   3.7752e-10,\n",
      "         1.6282e-14,   9.7912e-13,   2.8929e-12,   2.4198e-06,   1.0952e-05,   6.8742e-06,\n",
      "         5.7444e-05,   3.0641e-06,   4.6238e-05,   1.1339e-05,   9.7166e-04,   1.4416e-05,\n",
      "         4.5873e-04,   3.1598e-04,   1.7443e-05,   3.7675e-08,   7.9388e-05,   4.5797e-06,\n",
      "         8.7808e-06,   4.4030e-07,   1.2664e-04,   1.3194e-05,   2.9965e-07,   1.4718e-06,\n",
      "         1.2426e-03,   1.6375e-03,   5.0469e-05,   8.0136e-08,   2.2674e-05,   4.7976e-08,\n",
      "         2.6912e-07,   8.3019e-09,   2.4866e-12,   1.7455e-13,   8.8686e-11,   8.9595e-13,\n",
      "         9.2805e-14,   1.6012e-12], dtype=float32), array([  4.0333e-07,   1.3715e-04,   9.4897e-04,   3.7090e-05,   1.3983e-02,   8.8954e-05,\n",
      "         1.1947e-03,   4.7364e-05,   1.5702e-04,   6.1194e-05,   5.0818e-05,   7.9578e-08,\n",
      "         2.6654e-05,   5.7698e-06,   7.7743e-06,   8.8043e-06,   3.5287e-06,   2.5406e-06,\n",
      "         6.1106e-06,   6.6969e-06,   5.3277e-06,   8.0134e-05,   9.1523e-05,   8.4059e-06,\n",
      "         1.3825e-04,   5.7795e-04,   1.9407e-04,   1.7586e-03,   7.7154e-04,   1.3462e-03,\n",
      "         9.4757e-04,   1.8323e-03,   2.1570e-04,   1.3666e-03,   5.0610e-05,   2.5164e-04,\n",
      "         5.3847e-04,   4.7642e-04,   2.2054e-03,   6.3734e-04,   1.0356e-03,   1.6677e-05,\n",
      "         1.9000e-03,   1.9671e-03,   1.0961e-03,   1.7681e-04,   1.4427e-04,   1.5747e-03,\n",
      "         6.8010e-06,   1.6192e-04,   5.4765e-05,   1.2724e-03,   4.4235e-06,   1.5910e-03,\n",
      "         9.1813e-02,   2.4756e-02,   9.3760e-02,   2.6296e-02,   3.9434e-02,   4.6874e-02,\n",
      "         1.7050e-02,   3.8777e-02,   5.9096e-02,   2.3988e-03,   7.3044e-03,   2.0891e-02,\n",
      "         5.9786e-02,   3.5514e-02,   5.8428e-02,   6.2402e-02,   7.1677e-03,   1.8151e-02,\n",
      "         6.9718e-02,   8.5409e-02,   6.4352e-03,   1.0307e-02,   7.4446e-02,   1.1697e-04,\n",
      "         2.2520e-03,   1.2868e-04,   3.3686e-07,   1.0050e-05,   6.3286e-07,   6.7753e-07,\n",
      "         4.1170e-06,   2.1000e-07], dtype=float32), array([  2.7619e-11,   5.3199e-05,   2.6542e-03,   3.5657e-06,   7.0890e-06,   1.5861e-06,\n",
      "         1.4034e-11,   1.7174e-06,   5.9082e-05,   8.1943e-06,   4.7777e-05,   1.7156e-08,\n",
      "         2.3433e-07,   2.3521e-07,   1.8497e-07,   9.9086e-08,   3.6545e-08,   2.5551e-08,\n",
      "         4.8310e-08,   1.6843e-08,   1.4298e-07,   1.9131e-06,   1.9690e-07,   6.3000e-13,\n",
      "         9.5778e-06,   1.2725e-06,   4.7922e-07,   2.3307e-06,   1.2490e-07,   1.1652e-07,\n",
      "         6.2098e-06,   4.1402e-06,   2.5921e-09,   1.0267e-07,   6.0148e-11,   2.7995e-10,\n",
      "         6.1644e-07,   5.8060e-06,   6.5259e-05,   1.0838e-06,   1.5109e-06,   5.2825e-10,\n",
      "         2.2615e-06,   4.8034e-05,   8.1043e-07,   4.4650e-08,   9.3962e-07,   8.4755e-09,\n",
      "         3.1553e-08,   4.2205e-12,   2.3033e-09,   6.6050e-09,   2.5883e-07,   5.3549e-05,\n",
      "         2.1785e-03,   2.9690e-04,   4.8255e-04,   5.0039e-02,   1.1311e-03,   1.2487e-02,\n",
      "         1.9577e-03,   1.0892e-05,   9.4943e-07,   4.8352e-07,   2.4999e-05,   2.7315e-03,\n",
      "         7.3785e-02,   3.2984e-01,   1.7562e-04,   3.9738e-03,   1.9365e-05,   2.2623e-03,\n",
      "         4.3070e-01,   8.4076e-02,   2.4315e-04,   3.1987e-04,   1.9371e-06,   1.4075e-04,\n",
      "         8.5664e-08,   7.1089e-05,   2.7388e-15,   1.9099e-12,   5.7059e-11,   2.8729e-10,\n",
      "         2.6182e-12,   7.7972e-12], dtype=float32), array([  5.4035e-10,   5.0056e-02,   8.9690e-01,   1.1649e-03,   3.6161e-04,   5.4205e-06,\n",
      "         5.0981e-09,   3.1743e-04,   1.8473e-02,   2.4321e-03,   4.1967e-03,   5.9690e-09,\n",
      "         3.9012e-08,   8.7258e-09,   3.7144e-08,   5.4497e-08,   1.5363e-08,   5.5769e-09,\n",
      "         1.2086e-08,   6.1163e-09,   3.9171e-09,   9.7231e-04,   4.7895e-03,   9.8192e-06,\n",
      "         8.5972e-04,   1.5735e-06,   7.9245e-07,   5.0938e-07,   1.1337e-07,   3.5564e-06,\n",
      "         1.2226e-07,   1.0088e-07,   5.5496e-06,   2.4937e-06,   2.9570e-07,   2.5434e-08,\n",
      "         4.6794e-07,   1.2523e-06,   8.5238e-07,   4.4031e-08,   3.6513e-06,   7.9136e-08,\n",
      "         1.9672e-07,   6.9790e-06,   6.6006e-06,   6.9710e-08,   3.6712e-08,   2.3078e-08,\n",
      "         2.0813e-09,   5.8841e-08,   9.3937e-11,   1.5772e-05,   4.5849e-04,   2.5902e-05,\n",
      "         7.3024e-04,   1.5772e-04,   1.1661e-03,   5.6876e-05,   1.6108e-03,   6.7988e-04,\n",
      "         4.0503e-06,   9.7950e-04,   6.2677e-04,   6.3818e-06,   2.4251e-05,   6.9992e-05,\n",
      "         1.5160e-03,   7.9870e-05,   6.2295e-04,   3.3055e-03,   1.2036e-05,   3.1803e-05,\n",
      "         2.4179e-03,   4.3719e-03,   1.3921e-04,   1.2936e-04,   1.6891e-04,   2.9526e-07,\n",
      "         1.4666e-05,   1.8366e-07,   6.6253e-12,   1.2151e-11,   4.9265e-09,   3.4068e-10,\n",
      "         1.4303e-11,   5.4161e-10], dtype=float32)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['a', 'h', 'e', 's', ' ', 'c', 's', ' ']"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_nexts_keras(' this is')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### one-hot sequence model with keras\n",
    "\n",
    "This is the keras version of th theano model taht we're about to create."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hjkim\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: UserWarning: Update your `SimpleRNN` call to the Keras 2 API: `SimpleRNN(256, return_sequences=True, input_shape=(8, 86), activation=\"relu\", recurrent_initializer=\"identity\")`\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    SimpleRNN(n_hidden, return_sequences = True, input_shape = (cs, vocab_size), activation = 'relu', inner_init = 'identity'),\n",
    "    TimeDistributed(Dense(vocab_size, activation = 'softmax'))\n",
    "])\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer = Adam())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((75109, 8, 86), (75109, 8, 86))"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oh_ys = [to_categorical(o, vocab_size) for o in ys]\n",
    "oh_y_rnn = np.stack(oh_ys, axis = 1)\n",
    "\n",
    "oh_xs = [to_categorical(o, vocab_size) for o in xs]\n",
    "oh_x_rnn = np.stack(oh_xs, axis = 1)\n",
    "\n",
    "oh_x_rnn.shape, oh_y_rnn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "75109/75109 [==============================] - 48s - loss: 2.4485    \n",
      "Epoch 2/8\n",
      "75109/75109 [==============================] - 46s - loss: 2.0359    \n",
      "Epoch 3/8\n",
      "75109/75109 [==============================] - 46s - loss: 1.9211    \n",
      "Epoch 4/8\n",
      "75109/75109 [==============================] - 48s - loss: 1.8570    \n",
      "Epoch 5/8\n",
      "75109/75109 [==============================] - 59s - loss: 1.8141    - ETA: 0s - loss: 1\n",
      "Epoch 6/8\n",
      "75109/75109 [==============================] - 53s - loss: 1.7832    \n",
      "Epoch 7/8\n",
      "75109/75109 [==============================] - 47s - loss: 1.7599    \n",
      "Epoch 8/8\n",
      "34112/75109 [============>.................] - ETA: 25s - loss: 1.7406"
     ]
    }
   ],
   "source": [
    "model.fit(oh_x_rnn, oh_y_rnn, batch_size = 64, epochs = 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_nexts_oh(inp):\n",
    "    idxs = np.array([char_indices[c] for c in inp])\n",
    "    arr = to_categorical(idxs, vocab_size)\n",
    "    \n",
    "    p = model.predict(arr[np.newaxis, :])[0]\n",
    "    print(list(inp))\n",
    "    return [chars[np.argmax(o)] for o in p]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "get_nexts_oh(' this is')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
